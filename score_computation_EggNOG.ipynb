{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Computation EggNOG\n",
    "Author: Matteo Togninalli\n",
    "\n",
    "This is a short notebook to explore the orthology data collected by Dr. Kemal Avican (Umeå University). The dataset is composed of orthology groups information from genes of the different species.\n",
    "\n",
    "The eggNOG files are tab-delimited and contain the following columns\n",
    "* Locus tag: same as locus tags in DIFFx files\n",
    "* seed_eggNOG_ortholog: best protein match in eggNOG\n",
    "* seed_ortholog_evalue: best protein match (e-value)\n",
    "* seed_ortholog_score: best protein match (bit-score)\n",
    "* predicted_gene_name: Predicted gene name for query sequences\n",
    "* GO_terms: Comma delimited list of predicted Gene Ontology terms\n",
    "* KEGG_KO: Comma delimited list of predicted KEGG KOs\n",
    "* BiGG_Reactions: Comma delimited list of predicted BiGG metabolic reactions\n",
    "* Annotation_tax_scope: The taxonomic scope used to annotate this query sequence\n",
    "* Matching_OGs: Comma delimited list of matching eggNOG Orthologous Groups\n",
    "* best_OG|evalue|score: Best matching Orthologous Groups (only in HMM mode)\n",
    "* COG functional categories: COG functional category inferred from best matching OG\n",
    "* eggNOG_HMM_model_annotation: eggNOG functional description inferred from best matching \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "names = [\"locus_tag\",\"seed_eggnog_ortholog\",\"seed_ortholog_evalue\", \"seed_ortholog_score\", \"predicted_gene_name\", \n",
    "         \"GO_terms\",\"KEGG_KO\", \"BiGG_reactions\", \"Annotation_tax_scope\", \"Matching_OGs\", \"best_OG\", \n",
    "         \"cog_functional_categories\", \"eggNOG_HMM_model_annotation\"]\n",
    "df_eggnog = pd.read_csv(os.path.join(DATA_FOLDER, \"eggNOG\", \"Acinetobacter baumannii AB5075-UW.txt.emapper.annotations\"),\n",
    "                        sep=\"\\t\",names=names, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locus_tag</th>\n",
       "      <th>seed_eggnog_ortholog</th>\n",
       "      <th>seed_ortholog_evalue</th>\n",
       "      <th>seed_ortholog_score</th>\n",
       "      <th>predicted_gene_name</th>\n",
       "      <th>GO_terms</th>\n",
       "      <th>KEGG_KO</th>\n",
       "      <th>BiGG_reactions</th>\n",
       "      <th>Annotation_tax_scope</th>\n",
       "      <th>Matching_OGs</th>\n",
       "      <th>best_OG</th>\n",
       "      <th>cog_functional_categories</th>\n",
       "      <th>eggNOG_HMM_model_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABUW_RS00010</td>\n",
       "      <td>575584.HMPREF0010_03688</td>\n",
       "      <td>1.100000e-207</td>\n",
       "      <td>727.6</td>\n",
       "      <td>DNAN</td>\n",
       "      <td>GO:0003674,GO:0003824,GO:0003887,GO:0005575,GO...</td>\n",
       "      <td>K02338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05CZ8@bactNOG,0QHTG@gproNOG,16QFW@proNOG,COG05...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>DNA polymerase III is a complex, multichain en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUW_RS00015</td>\n",
       "      <td>575584.HMPREF0010_03689</td>\n",
       "      <td>9.100000e-204</td>\n",
       "      <td>714.5</td>\n",
       "      <td>RECF</td>\n",
       "      <td>GO:0000731,GO:0003674,GO:0003676,GO:0003677,GO...</td>\n",
       "      <td>K03629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05C3X@bactNOG,0QJ20@gproNOG,16Q55@proNOG,COG11...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>it is required for DNA replication and normal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABUW_RS00020</td>\n",
       "      <td>575584.HMPREF0010_03690</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1616.3</td>\n",
       "      <td>GYRB</td>\n",
       "      <td>GO:0000166,GO:0001882,GO:0001883,GO:0003674,GO...</td>\n",
       "      <td>K02470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05C7D@bactNOG,0QJ2B@gproNOG,16Q2I@proNOG,COG01...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>DNA gyrase negatively supercoils closed circul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABUW_RS00025</td>\n",
       "      <td>575584.HMPREF0010_03691</td>\n",
       "      <td>4.000000e-61</td>\n",
       "      <td>239.2</td>\n",
       "      <td>CYBC</td>\n",
       "      <td>GO:0005575,GO:0005623,GO:0042597,GO:0044464</td>\n",
       "      <td>K15536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>08XVM@bactNOG,0QRHQ@gproNOG,17B3X@proNOG,COG37...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>C</td>\n",
       "      <td>Cytochrome b(562)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABUW_RS00030</td>\n",
       "      <td>575584.HMPREF0010_03692</td>\n",
       "      <td>1.700000e-97</td>\n",
       "      <td>360.5</td>\n",
       "      <td>YQJA</td>\n",
       "      <td>GO:0000003,GO:0000910,GO:0005575,GO:0005623,GO...</td>\n",
       "      <td>K01077,K03975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>06W5V@bactNOG,0QJZ5@gproNOG,16RHI@proNOG,COG05...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>S</td>\n",
       "      <td>membrane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      locus_tag     seed_eggnog_ortholog  seed_ortholog_evalue  \\\n",
       "0  ABUW_RS00010  575584.HMPREF0010_03688         1.100000e-207   \n",
       "1  ABUW_RS00015  575584.HMPREF0010_03689         9.100000e-204   \n",
       "2  ABUW_RS00020  575584.HMPREF0010_03690          0.000000e+00   \n",
       "3  ABUW_RS00025  575584.HMPREF0010_03691          4.000000e-61   \n",
       "4  ABUW_RS00030  575584.HMPREF0010_03692          1.700000e-97   \n",
       "\n",
       "   seed_ortholog_score predicted_gene_name  \\\n",
       "0                727.6                DNAN   \n",
       "1                714.5                RECF   \n",
       "2               1616.3                GYRB   \n",
       "3                239.2                CYBC   \n",
       "4                360.5                YQJA   \n",
       "\n",
       "                                            GO_terms        KEGG_KO  \\\n",
       "0  GO:0003674,GO:0003824,GO:0003887,GO:0005575,GO...         K02338   \n",
       "1  GO:0000731,GO:0003674,GO:0003676,GO:0003677,GO...         K03629   \n",
       "2  GO:0000166,GO:0001882,GO:0001883,GO:0003674,GO...         K02470   \n",
       "3        GO:0005575,GO:0005623,GO:0042597,GO:0044464         K15536   \n",
       "4  GO:0000003,GO:0000910,GO:0005575,GO:0005623,GO...  K01077,K03975   \n",
       "\n",
       "  BiGG_reactions Annotation_tax_scope  \\\n",
       "0            NaN          bactNOG[38]   \n",
       "1            NaN          bactNOG[38]   \n",
       "2            NaN          bactNOG[38]   \n",
       "3            NaN          bactNOG[38]   \n",
       "4            NaN          bactNOG[38]   \n",
       "\n",
       "                                        Matching_OGs   best_OG  \\\n",
       "0  05CZ8@bactNOG,0QHTG@gproNOG,16QFW@proNOG,COG05...  NA|NA|NA   \n",
       "1  05C3X@bactNOG,0QJ20@gproNOG,16Q55@proNOG,COG11...  NA|NA|NA   \n",
       "2  05C7D@bactNOG,0QJ2B@gproNOG,16Q2I@proNOG,COG01...  NA|NA|NA   \n",
       "3  08XVM@bactNOG,0QRHQ@gproNOG,17B3X@proNOG,COG37...  NA|NA|NA   \n",
       "4  06W5V@bactNOG,0QJZ5@gproNOG,16RHI@proNOG,COG05...  NA|NA|NA   \n",
       "\n",
       "  cog_functional_categories                        eggNOG_HMM_model_annotation  \n",
       "0                         L  DNA polymerase III is a complex, multichain en...  \n",
       "1                         L  it is required for DNA replication and normal ...  \n",
       "2                         L  DNA gyrase negatively supercoils closed circul...  \n",
       "3                         C                                  Cytochrome b(562)  \n",
       "4                         S                                           membrane  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_eggnog.shape)\n",
    "df_eggnog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Achromobacter xylosoxidans SOLR10.txt.emapper.annotations',\n",
       " 'Acinetobacter baumannii AB5075-UW.txt.emapper.annotations',\n",
       " 'Aggregatibacter actinomycetemcomitans D7S-1.txt.emapper.annotations',\n",
       " 'Borrelia burgdorferi B31.txt.emapper.annotations',\n",
       " 'Burkholderia pseudomallei K96243.txt.emapper.annotations',\n",
       " 'Campylobacter jejuni subsp. jejuni 81-176.txt.emapper.annotations',\n",
       " 'Enterococcus faecalis OG1RF.txt.emapper.annotations',\n",
       " 'Escherichia coli EPEC 0127 H6 E2348 69.txt.emapper.annotations',\n",
       " 'Escherichia coli ETEC H10407.txt.emapper.annotations',\n",
       " 'Escherichia coli UPEC 536.txt.emapper.annotations',\n",
       " 'Francisella tularensis subsp. holarctica FSC200.txt.emapper.annotations',\n",
       " 'Haemophilus influenzae 86-028NP.txt.emapper.annotations',\n",
       " 'Helicobacter pylori G27.txt.emapper.annotations',\n",
       " 'Helicobacter pylori J99.txt.emapper.annotations',\n",
       " 'Klebsiella pneumoniae subsp. pneumoniae MGH 78578.txt.emapper.annotations',\n",
       " 'Legionella pneumophila subsp. pneumophila Philadelphia 1.txt.emapper.annotations',\n",
       " 'Listeria monocytogenes EGD-e.txt.emapper.annotations',\n",
       " 'Mycobacterium tuberculosis H37Ra.txt.emapper.annotations',\n",
       " 'Neisseria gonorrhoeae FA 1090.txt.emapper.annotations',\n",
       " 'Neisseria meningitidis serogroup C FAM18.txt.emapper.annotations',\n",
       " 'Pseudomonas aeruginosa PAO1.txt.emapper.annotations',\n",
       " 'Salmonella enterica subsp. enterica serovar TyphimuriumSL1344.txt.emapper.annotations',\n",
       " 'Shigella flexneri 5a str. M90T.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0aureus MRSA252.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0aureus MSSA476.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0epidermidis 1457.txt.emapper.annotations',\n",
       " 'Streptococcus agalactiae NEM316.txt.emapper.annotations',\n",
       " 'Streptococcus pneumoniae D39.txt.emapper.annotations',\n",
       " 'Streptococcus pyogenes 5448.txt.emapper.annotations',\n",
       " 'Streptococcus suis S10 P 17.txt.emapper.annotations',\n",
       " 'Vibrio cholerae O1 biovar El Tor str. N16961.txt.emapper.annotations',\n",
       " 'Yersinia pseudotuberculosis YPIII.txt.emapper.annotations']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to build dictionary tables to determine which GO\n",
    "# First let's load all the files and concatenate them\n",
    "csv_path = os.path.join(DATA_FOLDER,\"eggNOG\")\n",
    "filenames = []\n",
    "df_concat = []\n",
    "for file in os.listdir(csv_path):\n",
    "    # load the df\n",
    "    # Avoid junk files\n",
    "    if file.startswith('.'):\n",
    "        continue\n",
    "    df_pathogen = pd.read_csv(os.path.join(csv_path, file), sep=\"\\t\",names=names, skiprows=1)\n",
    "    filenames.append(file)\n",
    "    df_concat.append(df_pathogen)\n",
    "df_global = pd.concat(df_concat)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90669, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global['Matching_OGs'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list containing all the OGs in the dataset\n",
    "all_ogs = []\n",
    "for go in df_global['Matching_OGs'].unique():\n",
    "    if go and go!= 'nan':\n",
    "        # Only take the first og (bactNOG)\n",
    "        no_bactnog = True\n",
    "        for g in str(go).split(','):\n",
    "            if g.find('bact')>0:\n",
    "                no_bactnog=False\n",
    "                all_ogs.append(g)\n",
    "        if no_bactnog:\n",
    "            all_ogs += [*str(go).split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20792,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ogs = np.unique(all_ogs)\n",
    "all_ogs.shape # Total number of unique OGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of counters\n",
    "counter_all_ogs = dict()\n",
    "for og in all_ogs:\n",
    "    counter_all_ogs[og] = 0\n",
    "for df_patho in df_concat:\n",
    "    # Get all ko for that species\n",
    "    patho_ogs = []\n",
    "    for og_sp in df_patho['Matching_OGs'].unique():\n",
    "        if og_sp and og_sp != 'nan':\n",
    "            no_bactnog = og_sp.find('bact')<0\n",
    "            for g in str(og_sp).split(','):\n",
    "                if no_bactnog:\n",
    "                    patho_ogs.append(g)\n",
    "                    counter_all_ogs[g]+=1\n",
    "                else:\n",
    "                    if g.find('bact')>0:\n",
    "                        patho_ogs.append(g)\n",
    "                        counter_all_ogs[g]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to build a dictionary for each species gene name to the KO, when multiple are available, map them to all\n",
    "# A first clustering approach would use a gene x species matrix, one for each condition, \n",
    "# missing values can be left blank (filtered out), or zero-/mean-imputed\n",
    "\n",
    "# Assumption: we cluster KOs, irrespective if they match to more than one species\n",
    "def get_bactnog(string):\n",
    "    for g in str(string).split(','):\n",
    "        if g.find('bact')>0:\n",
    "            return g\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "def get_species_dict(df_patho):\n",
    "    og_dict = defaultdict(list)\n",
    "    locus_dict = dict()\n",
    "    # Build the kos map from\n",
    "    for locus, og_r in zip(df_patho['locus_tag'], df_patho['Matching_OGs']):\n",
    "        locus_dict[locus] = get_bactnog(og_r)\n",
    "        if og_r and og_r!= 'nan':\n",
    "            no_bactnog = og_r.find('bact')<0\n",
    "            for g in str(og_r).split(','):\n",
    "                if no_bactnog:\n",
    "                    og_dict[g].append(locus)\n",
    "                else:\n",
    "                    if g.find('bact')>0:\n",
    "                        og_dict[g].append(locus)\n",
    "                        break\n",
    "    return og_dict, locus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master dict for all KOs\n",
    "master_dict = defaultdict(list)\n",
    "loci_dict = []\n",
    "for df_patho in df_concat:\n",
    "    o_dict, l_dict = get_species_dict(df_patho)\n",
    "    loci_dict.append(l_dict)\n",
    "    for og in all_ogs:\n",
    "        if og in o_dict:\n",
    "            master_dict[og].append(o_dict[og])\n",
    "        else:\n",
    "            master_dict[og].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the list of genes for each orthology group.\n",
    "columns = ['.'.join(f.split('.')[:-3]) for f in filenames]\n",
    "df_og_mapping = pd.DataFrame.from_dict(master_dict, orient='index', columns=columns)\n",
    "\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "df_og_mapping['n_genes_total'] = df_og_mapping.index.map(lambda x: count_total_genes(x, master_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20792, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_og_mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "df_og_mapping.to_csv(os.path.join(OUTPUT_FOLDER,'eggnog_gene_list.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we build the gene expression matrix, one for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Rename columns for faster access later on\n",
    "def clean_dataframe(df_gene_expr):\n",
    "    # Quick function to get rid of log fold change columns and to rename columns\n",
    "    # condition_max, condition_fold, condition_p, condition_p_fdr, condition_p_bonf\n",
    "    # First, drop the columns after 75\n",
    "    # Some species have, for some reason, more meta-information\n",
    "    meta_columns = 9\n",
    "    if df_gene_expr.shape[1]>219:\n",
    "        # Some files have more meta columns...\n",
    "        meta_columns = 14\n",
    "        \n",
    "    df_gene_expr = df_gene_expr.drop(columns=df_gene_expr.columns[66+meta_columns:])\n",
    "    \n",
    "    # Find conditions names\n",
    "    unique_conditions = list(set(map(lambda x: x.split(' ')[0], df_gene_expr.columns[meta_columns:].tolist())))\n",
    "    # Create new keys dictionnary:\n",
    "    new_keys = dict()\n",
    "    for column in df_gene_expr.columns[5:].tolist():\n",
    "        if column.split(\" \")[-1] == \"means\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_max\"\n",
    "        elif column.split(\" \")[-1] == \"change\":\n",
    "            if column.split(\" \")[-2] == \"fold\":\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_logfold\"\n",
    "            else:\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_fold\"\n",
    "        elif column.split(\" \")[-1] == \"P-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p\"\n",
    "        elif column.split(\" \")[-1] == \"p-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_fdr\"\n",
    "        elif column.split(\" \")[-1] == \"Bonferroni\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_bonf\"\n",
    "    return df_gene_expr.rename(new_keys, axis=\"columns\").rename(str.lower, axis=\"columns\")\n",
    "\n",
    "def count_genes_with_filtering(df_gene_expr, filtering_criteria=None):\n",
    "    # Returns the number of genes with a specific set of filtering criteria \n",
    "    # passed as a dictionary of fold_change, max_group_means and fdr_pvalue\n",
    "    # If no criteria are passed, simply returns the total number of genes\n",
    "    if filtering_criteria == None:\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    else:\n",
    "        # Check group means\n",
    "        if \"max_group_means\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                b_index = np.logical_or(b_index, (df_gene_expr[c + \"_max\"] > filtering_criteria[\"max_group_means\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fold_change\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (np.abs(df_gene_expr[c + \"_fold\"]) > filtering_criteria[\"fold_change\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fdr_pvalue\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (df_gene_expr[c + \"_fold\"] < filtering_criteria[\"fdr_pvalue\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data matrix X\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_kos, ko_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for ko in all_kos:\n",
    "        # Retrieve the original name\n",
    "        locus_name = ko_dict[ko][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the information across species (we might have lost a bit of information for genes with no known Kegg Orthology) we will now analyse the results for the different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data array X (WITH VARIABLE LENGTH)\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_ogs, og_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for og in all_ogs:\n",
    "        # Retrieve the original name\n",
    "        locus_name = og_dict[og][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n",
    "\n",
    "def count_activated_genes(df_pathogen, locus_names, conditions, filters):\n",
    "    # Returns a count array of activation across conditions for multiple loci\n",
    "    # Returns both positive and negative counts\n",
    "    logf_col = [\"{}_logfold\".format(x) for x in conditions]\n",
    "    pval_col = [\"{}_p\".format(x) for x in conditions]\n",
    "    max_col = [\"{}_max\".format(x) for x in conditions]\n",
    "    ltag = 'new_locus_tag'\n",
    "    if df_pathogen['new_locus_tag'].isna().all():\n",
    "        ltag = 'old_locus_tag'\n",
    "    expr = df_pathogen[df_pathogen[ltag].isin(locus_names)][logf_col].to_numpy()\n",
    "    pv = df_pathogen[df_pathogen[ltag].isin(locus_names)][pval_col].to_numpy()\n",
    "    max_val = df_pathogen[df_pathogen[ltag].isin(locus_names)][max_col].to_numpy()\n",
    "    filter_p_max = np.logical_and(pv < filters['pvalue'], \n",
    "                                  max_val > filters['max'])\n",
    "    return np.logical_and(expr > filters['logfold'], filter_p_max).sum(axis=0), \\\n",
    "            np.logical_and(expr < -filters['logfold'], filter_p_max).sum(axis=0)\n",
    "    \n",
    "\n",
    "def get_activated_gene_count(df_pathogen, all_ogs, og_dict, idx, conditions, filters):\n",
    "    # Return a matrix with the count of genes above a determined threshold for each conditions\n",
    "    # Filters is a dict with a logfold and a pvalue entries\n",
    "    mat_upreg = []\n",
    "    mat_downreg = []\n",
    "    for og in all_ogs:\n",
    "        locus_names = og_dict[og][idx]\n",
    "        # If the KO doesn't have a mapping in this species return NaNs\n",
    "        if locus_names is None:\n",
    "            counts_up = np.empty((len(conditions),))\n",
    "            counts_up[:] = np.nan\n",
    "            counts_down = np.empty((len(conditions),))\n",
    "            counts_down[:] = np.nan\n",
    "        else:\n",
    "            counts_up, counts_down = count_activated_genes(df_pathogen, locus_names, conditions, filters)\n",
    "        mat_upreg.append(counts_up)\n",
    "        mat_downreg.append(counts_down)\n",
    "    return np.asarray(mat_upreg), np.asarray(mat_downreg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "Burkholderia pseudomallei K96243\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli UPEC 536\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "Helicobacter pylori G27\n",
      "Helicobacter pylori J99\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus aureus MRSA252\n",
      "Staphylococcus aureus MSSA476\n",
      "Staphylococcus epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "# There will be one matrix per columns\n",
    "matrices_upregulated = dict()\n",
    "matrices_downregulated = dict()\n",
    "for c in columns:\n",
    "    matrices_upregulated[c] = []\n",
    "    matrices_downregulated[c] = []\n",
    "names = []\n",
    "expression_path = os.path.join(DATA_FOLDER, 'expression')\n",
    "\n",
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "condition_species_count = dict()\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    condition_species_count[cond] = 0\n",
    "\n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    name = \".\".join(file.split(\".\")[:-3])\n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    # Get all expressions\n",
    "    count_matrix_upreg, count_matrix_downreg = get_activated_gene_count(df_pathogen, \n",
    "                                                                        all_ogs, master_dict, \n",
    "                                                                        i, conditions, filters)\n",
    "    \n",
    "    # Count actual species count\n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: condition_species_count[col] += 1\n",
    "            \n",
    "    # Check for columns\n",
    "    col_eff = []\n",
    "    for j,col in enumerate(columns):\n",
    "        if (df_pathogen[col].isna()).all():\n",
    "            x_up = np.empty((len(all_ogs,)))\n",
    "            x_up[:] = None\n",
    "            x_down = np.empty((len(all_ogs,)))\n",
    "            x_down[:] = None\n",
    "        else:\n",
    "            x_up = count_matrix_upreg[:,j]\n",
    "            x_down = count_matrix_downreg[:,j]\n",
    "        matrices_upregulated[col].append(x_up)\n",
    "        matrices_downregulated[col].append(x_down)\n",
    "    names.append(name)\n",
    "    \n",
    "for col in columns:\n",
    "    matrices_upregulated[col] = np.asarray(matrices_upregulated[col]).T\n",
    "    matrices_downregulated[col] = np.asarray(matrices_downregulated[col]).T    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# SCORE COMPUTATION HERE\n",
    "# ----------------------------------------------------------------------\n",
    "NTOT = 32\n",
    "\n",
    "# New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "scores_combined_new = []\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "# 1. REGULAR SCORE, WITH ABSOLUTE COUNT\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_EGGNOG = os.path.join(OUTPUT_FOLDER, 'eggnog_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_EGGNOG, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"master_score.csv\"), index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_EGGNOG, \"absolute_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_df.loc[scores_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"absolute_score_top100\",\"{}_top100_on.csv\".format(cond)), index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directional score\n",
    "\n",
    "The directional score is a modification of the original score:\n",
    "\n",
    "$$S_{cond}=\\frac{1+ | n_{genes}(upreg)-n_{genes}(downreg)|}{1+n_{genes}(total)} \\frac{n_{species}(on)}{\\sqrt{n_{species}(total) \\cdot n_{species}(db)}} \\cdot log_2(1+n_{genes}(on))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SCORE WITH DIRECTIONALITY TAKEN INTO ACCOUNT\n",
    "scores_combined_new = []\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "    scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_new_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_EGGNOG = os.path.join(OUTPUT_FOLDER, 'eggnog_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_EGGNOG, exist_ok=True)\n",
    "master_scores_df = scores_new_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"master_directionality_score.csv\"), index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_EGGNOG, \"directionality_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_new_df.loc[scores_new_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on_upregulated'] = pd.DataFrame(matrices_upregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on_downregulated'] = pd.DataFrame(matrices_downregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"directionality_score_top100\",\"{}_top100_on.csv\".format(cond)),\n",
    "                     index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores with subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group the bacteria in subclasses\n",
    "df_subgroups = pd.read_excel(os.path.join(DATA_FOLDER,'Groups_of_bacteria.xlsx'))\n",
    "\n",
    "# Get all unique classes\n",
    "GROUPS = ['Lifestyle', 'Infection', 'Class', 'Respiration', 'Gram St.']\n",
    "def get_unique_classes(ll):\n",
    "    # returns a truly unique set of values for each class\n",
    "    all_ll = []\n",
    "    for l in ll:\n",
    "        all_ll.extend([x.split(' ')[-1] for x in l.split(',')])\n",
    "    return np.unique(all_ll)\n",
    "\n",
    "def generate_bacteria_set(df_subgroup, group):\n",
    "    # Function that returns a list of species for each subgroup\n",
    "    subgroups = get_unique_classes(df_subgroup[group])\n",
    "    bacteria_dict = dict()\n",
    "    for subgroup in subgroups:\n",
    "        bact = []\n",
    "        for i, row in df_subgroup.iterrows():\n",
    "            if subgroup in [x.split(' ')[-1] for x in row[group].split(',')]:\n",
    "                bact.append(row['Species'])\n",
    "        bacteria_dict[subgroup] = bact\n",
    "    return bacteria_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "\tbs\n",
      "Burkholderia pseudomallei K96243\n",
      "\tbs\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli UPEC 536\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "\tbs\n",
      "Helicobacter pylori G27\n",
      "\tbs\n",
      "Helicobacter pylori J99\n",
      "\tbs\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "\tvic\n",
      "\tbs\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "\tvic\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus aureus MRSA252\n",
      "Staphylococcus aureus MSSA476\n",
      "Staphylococcus epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "\tmig\n",
      "\tsp\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "species_condition_list = defaultdict(list)\n",
    "\n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    name = \".\".join(file.split(\".\")[:-3])\n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    \n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: \n",
    "            species_condition_list[name].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "\n",
    "def get_species_db(species_condition_list, species_subset):\n",
    "    # Count the exact number of species for each condition in a given subset\n",
    "    cond_dict = dict()\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        cond_dict[cond] = 0\n",
    "        for sp in species_subset:\n",
    "            if cond in species_condition_list[sp]:\n",
    "                cond_dict[cond] += 1\n",
    "    return cond_dict\n",
    "        \n",
    "\n",
    "# Count genes for subset only\n",
    "def count_total_genes_species_subset(index, master_dict, indeces):\n",
    "    c = 0\n",
    "    for l in np.array(master_dict[index], dtype=object)[indeces]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "\n",
    "# Function to compute the score for a subset of species:\n",
    "def get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 species_subset, species_condition_list, directionality=False):\n",
    "    # New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "    scores_combined_new = []\n",
    "    \n",
    "    # Get Species indeces\n",
    "    indeces = []\n",
    "    sp_names = []\n",
    "    for i,file in enumerate(filenames):\n",
    "        name = \".\".join(file.split(\".\")[:-3])\n",
    "        if name in species_subset:\n",
    "            indeces.append(i)\n",
    "            sp_names.append(name)\n",
    "            \n",
    "    ntot = len(species_subset)\n",
    "    # Get count of species\n",
    "    cond_dict_count = get_species_db(species_condition_list, species_subset)\n",
    "\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces]+\n",
    "                                matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "        \n",
    "        if directionality:\n",
    "            df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "            df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "\n",
    "        # Get the total number of gene for each KO\n",
    "        total_genes = np.array([count_total_genes_species_subset(i, master_dict, indeces) for i in df_count.index])\n",
    "\n",
    "        # Get the number of species for that condition\n",
    "        n_species_db = cond_dict_count[cond]\n",
    "\n",
    "        # Compute score\n",
    "        if directionality:\n",
    "            # Compute score\n",
    "            x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "            scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        else:\n",
    "            scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        scores_combined_new.append(scores.to_numpy())\n",
    "    logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "    scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n",
    "    master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "    master_scores_df['n_genes_total'] = [count_total_genes_species_subset(i, master_dict, indeces) for i in master_scores_df.index]\n",
    "    master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "    return master_scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in GROUPS:\n",
    "    # Mkdir \n",
    "    subgroups = get_unique_classes(df_subgroups[group])\n",
    "    bact_dict = generate_bacteria_set(df_subgroups, group)\n",
    "    for subgroup in subgroups:\n",
    "        # make directory\n",
    "        path = os.path.join(OUTPUT_FOLDER_EGGNOG, group, subgroup)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        # Get species subset:\n",
    "        sp_subset = bact_dict[subgroup]\n",
    "        master_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=False)\n",
    "        master_df.to_csv(os.path.join(path, \"eggnog_master_score.csv\"), index=True, header=True)\n",
    "\n",
    "        \n",
    "        scores_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=True)\n",
    "        master_df.to_csv(os.path.join(path, \"eggnog_master_directionality_score.csv\"), index=True, header=True)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "testvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

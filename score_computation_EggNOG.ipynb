{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Computation EggNOG\n",
    "Author: Matteo Togninalli\n",
    "\n",
    "This is a short notebook to explore the orthology data collected by Dr. Kemal Avican (Ume√• University). The dataset is composed of orthology groups information from genes of the different species.\n",
    "\n",
    "The eggNOG files are tab-delimited and contain the following columns\n",
    "* Locus tag: same as locus tags in DIFFx files\n",
    "* seed_eggNOG_ortholog: best protein match in eggNOG\n",
    "* seed_ortholog_evalue: best protein match (e-value)\n",
    "* seed_ortholog_score: best protein match (bit-score)\n",
    "* predicted_gene_name: Predicted gene name for query sequences\n",
    "* GO_terms: Comma delimited list of predicted Gene Ontology terms\n",
    "* KEGG_KO: Comma delimited list of predicted KEGG KOs\n",
    "* BiGG_Reactions: Comma delimited list of predicted BiGG metabolic reactions\n",
    "* Annotation_tax_scope: The taxonomic scope used to annotate this query sequence\n",
    "* Matching_OGs: Comma delimited list of matching eggNOG Orthologous Groups\n",
    "* best_OG|evalue|score: Best matching Orthologous Groups (only in HMM mode)\n",
    "* COG functional categories: COG functional category inferred from best matching OG\n",
    "* eggNOG_HMM_model_annotation: eggNOG functional description inferred from best matching \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "OUTPUT_FOLDER = \"output\"\n",
    "names = [\"locus_tag\",\"seed_eggnog_ortholog\",\"seed_ortholog_evalue\", \"seed_ortholog_score\", \"predicted_gene_name\", \n",
    "         \"GO_terms\",\"KEGG_KO\", \"BiGG_reactions\", \"Annotation_tax_scope\", \"Matching_OGs\", \"best_OG\", \n",
    "         \"cog_functional_categories\", \"eggNOG_HMM_model_annotation\"]\n",
    "df_eggnog = pd.read_csv(os.path.join(DATA_FOLDER, \"eggNOG\", \"Acinetobacter baumannii AB5075-UW.txt.emapper.annotations\"),\n",
    "                        sep=\"\\t\",names=names, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locus_tag</th>\n",
       "      <th>seed_eggnog_ortholog</th>\n",
       "      <th>seed_ortholog_evalue</th>\n",
       "      <th>seed_ortholog_score</th>\n",
       "      <th>predicted_gene_name</th>\n",
       "      <th>GO_terms</th>\n",
       "      <th>KEGG_KO</th>\n",
       "      <th>BiGG_reactions</th>\n",
       "      <th>Annotation_tax_scope</th>\n",
       "      <th>Matching_OGs</th>\n",
       "      <th>best_OG</th>\n",
       "      <th>cog_functional_categories</th>\n",
       "      <th>eggNOG_HMM_model_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABUW_RS00010</td>\n",
       "      <td>575584.HMPREF0010_03688</td>\n",
       "      <td>1.100000e-207</td>\n",
       "      <td>727.6</td>\n",
       "      <td>DNAN</td>\n",
       "      <td>GO:0003674,GO:0003824,GO:0003887,GO:0005575,GO...</td>\n",
       "      <td>K02338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05CZ8@bactNOG,0QHTG@gproNOG,16QFW@proNOG,COG05...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>DNA polymerase III is a complex, multichain en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABUW_RS00015</td>\n",
       "      <td>575584.HMPREF0010_03689</td>\n",
       "      <td>9.100000e-204</td>\n",
       "      <td>714.5</td>\n",
       "      <td>RECF</td>\n",
       "      <td>GO:0000731,GO:0003674,GO:0003676,GO:0003677,GO...</td>\n",
       "      <td>K03629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05C3X@bactNOG,0QJ20@gproNOG,16Q55@proNOG,COG11...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>it is required for DNA replication and normal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABUW_RS00020</td>\n",
       "      <td>575584.HMPREF0010_03690</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1616.3</td>\n",
       "      <td>GYRB</td>\n",
       "      <td>GO:0000166,GO:0001882,GO:0001883,GO:0003674,GO...</td>\n",
       "      <td>K02470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>05C7D@bactNOG,0QJ2B@gproNOG,16Q2I@proNOG,COG01...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>L</td>\n",
       "      <td>DNA gyrase negatively supercoils closed circul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABUW_RS00025</td>\n",
       "      <td>575584.HMPREF0010_03691</td>\n",
       "      <td>4.000000e-61</td>\n",
       "      <td>239.2</td>\n",
       "      <td>CYBC</td>\n",
       "      <td>GO:0005575,GO:0005623,GO:0042597,GO:0044464</td>\n",
       "      <td>K15536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>08XVM@bactNOG,0QRHQ@gproNOG,17B3X@proNOG,COG37...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>C</td>\n",
       "      <td>Cytochrome b(562)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABUW_RS00030</td>\n",
       "      <td>575584.HMPREF0010_03692</td>\n",
       "      <td>1.700000e-97</td>\n",
       "      <td>360.5</td>\n",
       "      <td>YQJA</td>\n",
       "      <td>GO:0000003,GO:0000910,GO:0005575,GO:0005623,GO...</td>\n",
       "      <td>K01077,K03975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bactNOG[38]</td>\n",
       "      <td>06W5V@bactNOG,0QJZ5@gproNOG,16RHI@proNOG,COG05...</td>\n",
       "      <td>NA|NA|NA</td>\n",
       "      <td>S</td>\n",
       "      <td>membrane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      locus_tag     seed_eggnog_ortholog  seed_ortholog_evalue  \\\n",
       "0  ABUW_RS00010  575584.HMPREF0010_03688         1.100000e-207   \n",
       "1  ABUW_RS00015  575584.HMPREF0010_03689         9.100000e-204   \n",
       "2  ABUW_RS00020  575584.HMPREF0010_03690          0.000000e+00   \n",
       "3  ABUW_RS00025  575584.HMPREF0010_03691          4.000000e-61   \n",
       "4  ABUW_RS00030  575584.HMPREF0010_03692          1.700000e-97   \n",
       "\n",
       "   seed_ortholog_score predicted_gene_name  \\\n",
       "0                727.6                DNAN   \n",
       "1                714.5                RECF   \n",
       "2               1616.3                GYRB   \n",
       "3                239.2                CYBC   \n",
       "4                360.5                YQJA   \n",
       "\n",
       "                                            GO_terms        KEGG_KO  \\\n",
       "0  GO:0003674,GO:0003824,GO:0003887,GO:0005575,GO...         K02338   \n",
       "1  GO:0000731,GO:0003674,GO:0003676,GO:0003677,GO...         K03629   \n",
       "2  GO:0000166,GO:0001882,GO:0001883,GO:0003674,GO...         K02470   \n",
       "3        GO:0005575,GO:0005623,GO:0042597,GO:0044464         K15536   \n",
       "4  GO:0000003,GO:0000910,GO:0005575,GO:0005623,GO...  K01077,K03975   \n",
       "\n",
       "  BiGG_reactions Annotation_tax_scope  \\\n",
       "0            NaN          bactNOG[38]   \n",
       "1            NaN          bactNOG[38]   \n",
       "2            NaN          bactNOG[38]   \n",
       "3            NaN          bactNOG[38]   \n",
       "4            NaN          bactNOG[38]   \n",
       "\n",
       "                                        Matching_OGs   best_OG  \\\n",
       "0  05CZ8@bactNOG,0QHTG@gproNOG,16QFW@proNOG,COG05...  NA|NA|NA   \n",
       "1  05C3X@bactNOG,0QJ20@gproNOG,16Q55@proNOG,COG11...  NA|NA|NA   \n",
       "2  05C7D@bactNOG,0QJ2B@gproNOG,16Q2I@proNOG,COG01...  NA|NA|NA   \n",
       "3  08XVM@bactNOG,0QRHQ@gproNOG,17B3X@proNOG,COG37...  NA|NA|NA   \n",
       "4  06W5V@bactNOG,0QJZ5@gproNOG,16RHI@proNOG,COG05...  NA|NA|NA   \n",
       "\n",
       "  cog_functional_categories                        eggNOG_HMM_model_annotation  \n",
       "0                         L  DNA polymerase III is a complex, multichain en...  \n",
       "1                         L  it is required for DNA replication and normal ...  \n",
       "2                         L  DNA gyrase negatively supercoils closed circul...  \n",
       "3                         C                                  Cytochrome b(562)  \n",
       "4                         S                                           membrane  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_eggnog.shape)\n",
    "df_eggnog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Achromobacter xylosoxidans SOLR10.txt.emapper.annotations',\n",
       " 'Acinetobacter baumannii AB5075-UW.txt.emapper.annotations',\n",
       " 'Aggregatibacter actinomycetemcomitans D7S-1.txt.emapper.annotations',\n",
       " 'Borrelia burgdorferi B31.txt.emapper.annotations',\n",
       " 'Burkholderia pseudomallei K96243.txt.emapper.annotations',\n",
       " 'Campylobacter jejuni subsp. jejuni 81-176.txt.emapper.annotations',\n",
       " 'Enterococcus faecalis OG1RF.txt.emapper.annotations',\n",
       " 'Escherichia coli EPEC 0127 H6 E2348 69.txt.emapper.annotations',\n",
       " 'Escherichia coli ETEC H10407.txt.emapper.annotations',\n",
       " 'Escherichia coli UPEC 536.txt.emapper.annotations',\n",
       " 'Francisella tularensis subsp. holarctica FSC200.txt.emapper.annotations',\n",
       " 'Haemophilus influenzae 86-028NP.txt.emapper.annotations',\n",
       " 'Helicobacter pylori G27.txt.emapper.annotations',\n",
       " 'Helicobacter pylori J99.txt.emapper.annotations',\n",
       " 'Klebsiella pneumoniae subsp. pneumoniae MGH 78578.txt.emapper.annotations',\n",
       " 'Legionella pneumophila subsp. pneumophila Philadelphia 1.txt.emapper.annotations',\n",
       " 'Listeria monocytogenes EGD-e.txt.emapper.annotations',\n",
       " 'Mycobacterium tuberculosis H37Ra.txt.emapper.annotations',\n",
       " 'Neisseria gonorrhoeae FA 1090.txt.emapper.annotations',\n",
       " 'Neisseria meningitidis serogroup C FAM18.txt.emapper.annotations',\n",
       " 'Pseudomonas aeruginosa PAO1.txt.emapper.annotations',\n",
       " 'Salmonella enterica subsp. enterica serovar TyphimuriumSL1344.txt.emapper.annotations',\n",
       " 'Shigella flexneri 5a str. M90T.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0aureus MRSA252.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0aureus MSSA476.txt.emapper.annotations',\n",
       " 'Staphylococcus\\xa0epidermidis 1457.txt.emapper.annotations',\n",
       " 'Streptococcus agalactiae NEM316.txt.emapper.annotations',\n",
       " 'Streptococcus pneumoniae D39.txt.emapper.annotations',\n",
       " 'Streptococcus pyogenes 5448.txt.emapper.annotations',\n",
       " 'Streptococcus suis S10 P 17.txt.emapper.annotations',\n",
       " 'Vibrio cholerae O1 biovar El Tor str. N16961.txt.emapper.annotations',\n",
       " 'Yersinia pseudotuberculosis YPIII.txt.emapper.annotations']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to build dictionary tables to determine which GO\n",
    "# First let's load all the files and concatenate them\n",
    "csv_path = os.path.join(DATA_FOLDER,\"eggNOG\")\n",
    "filenames = []\n",
    "df_concat = []\n",
    "for file in os.listdir(csv_path):\n",
    "    # load the df\n",
    "    # Avoid junk files\n",
    "    if file.startswith('.'):\n",
    "        continue\n",
    "    df_pathogen = pd.read_csv(os.path.join(csv_path, file), sep=\"\\t\",names=names, skiprows=1)\n",
    "    filenames.append(file)\n",
    "    df_concat.append(df_pathogen)\n",
    "df_global = pd.concat(df_concat)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90669, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global['Matching_OGs'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list containing all the OGs in the dataset\n",
    "all_ogs = []\n",
    "for go in df_global['Matching_OGs'].unique():\n",
    "    if go and go!= 'nan':\n",
    "        # Only take the first og (bactNOG)\n",
    "        no_bactnog = True\n",
    "        for g in str(go).split(','):\n",
    "            if g.find('bact')>0:\n",
    "                no_bactnog=False\n",
    "                all_ogs.append(g)\n",
    "        if no_bactnog:\n",
    "            all_ogs += [*str(go).split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20792,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ogs = np.unique(all_ogs)\n",
    "all_ogs.shape # Total number of unique OGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of counters\n",
    "counter_all_ogs = dict()\n",
    "for og in all_ogs:\n",
    "    counter_all_ogs[og] = 0\n",
    "for df_patho in df_concat:\n",
    "    # Get all ko for that species\n",
    "    patho_ogs = []\n",
    "    for og_sp in df_patho['Matching_OGs'].unique():\n",
    "        if og_sp and og_sp != 'nan':\n",
    "            no_bactnog = og_sp.find('bact')<0\n",
    "            for g in str(og_sp).split(','):\n",
    "                if no_bactnog:\n",
    "                    patho_ogs.append(g)\n",
    "                    counter_all_ogs[g]+=1\n",
    "                else:\n",
    "                    if g.find('bact')>0:\n",
    "                        patho_ogs.append(g)\n",
    "                        counter_all_ogs[g]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to build a dictionary for each species gene name to the KO, when multiple are available, map them to all\n",
    "# A first clustering approach would use a gene x species matrix, one for each condition, \n",
    "# missing values can be left blank (filtered out), or zero-/mean-imputed\n",
    "\n",
    "# Assumption: we cluster KOs, irrespective if they match to more than one species\n",
    "def get_bactnog(string):\n",
    "    for g in str(string).split(','):\n",
    "        if g.find('bact')>0:\n",
    "            return g\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "def get_species_dict(df_patho):\n",
    "    og_dict = defaultdict(list)\n",
    "    locus_dict = dict()\n",
    "    # Build the kos map from\n",
    "    for locus, og_r in zip(df_patho['locus_tag'], df_patho['Matching_OGs']):\n",
    "        locus_dict[locus] = get_bactnog(og_r)\n",
    "        if og_r and og_r!= 'nan':\n",
    "            no_bactnog = og_r.find('bact')<0\n",
    "            for g in str(og_r).split(','):\n",
    "                if no_bactnog:\n",
    "                    og_dict[g].append(locus)\n",
    "                else:\n",
    "                    if g.find('bact')>0:\n",
    "                        og_dict[g].append(locus)\n",
    "                        break\n",
    "    return og_dict, locus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master dict for all KOs\n",
    "master_dict = defaultdict(list)\n",
    "loci_dict = []\n",
    "for df_patho in df_concat:\n",
    "    o_dict, l_dict = get_species_dict(df_patho)\n",
    "    loci_dict.append(l_dict)\n",
    "    for og in all_ogs:\n",
    "        if og in o_dict:\n",
    "            master_dict[og].append(o_dict[og])\n",
    "        else:\n",
    "            master_dict[og].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the list of genes for each orthology group.\n",
    "columns = ['.'.join(f.split('.')[:-3]) for f in filenames]\n",
    "df_og_mapping = pd.DataFrame.from_dict(master_dict, orient='index', columns=columns)\n",
    "\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "df_og_mapping['n_genes_total'] = df_og_mapping.index.map(lambda x: count_total_genes(x, master_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20792, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_og_mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "df_og_mapping.to_csv(os.path.join(OUTPUT_FOLDER,'eggnog_gene_list.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we build the gene expression matrix, one for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# Rename columns for faster access later on\n",
    "def clean_dataframe(df_gene_expr):\n",
    "    # Quick function to get rid of log fold change columns and to rename columns\n",
    "    # condition_max, condition_fold, condition_p, condition_p_fdr, condition_p_bonf\n",
    "    # First, drop the columns after 75\n",
    "    # Some species have, for some reason, more meta-information\n",
    "    meta_columns = 9\n",
    "    if df_gene_expr.shape[1]>219:\n",
    "        # Some files have more meta columns...\n",
    "        meta_columns = 14\n",
    "        \n",
    "    df_gene_expr = df_gene_expr.drop(columns=df_gene_expr.columns[66+meta_columns:])\n",
    "    \n",
    "    # Find conditions names\n",
    "    unique_conditions = list(set(map(lambda x: x.split(' ')[0], df_gene_expr.columns[meta_columns:].tolist())))\n",
    "    # Create new keys dictionnary:\n",
    "    new_keys = dict()\n",
    "    for column in df_gene_expr.columns[5:].tolist():\n",
    "        if column.split(\" \")[-1] == \"means\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_max\"\n",
    "        elif column.split(\" \")[-1] == \"change\":\n",
    "            if column.split(\" \")[-2] == \"fold\":\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_logfold\"\n",
    "            else:\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_fold\"\n",
    "        elif column.split(\" \")[-1] == \"P-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p\"\n",
    "        elif column.split(\" \")[-1] == \"p-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_fdr\"\n",
    "        elif column.split(\" \")[-1] == \"Bonferroni\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_bonf\"\n",
    "    return df_gene_expr.rename(new_keys, axis=\"columns\").rename(str.lower, axis=\"columns\")\n",
    "\n",
    "def count_genes_with_filtering(df_gene_expr, filtering_criteria=None):\n",
    "    # Returns the number of genes with a specific set of filtering criteria \n",
    "    # passed as a dictionary of fold_change, max_group_means and fdr_pvalue\n",
    "    # If no criteria are passed, simply returns the total number of genes\n",
    "    if filtering_criteria == None:\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    else:\n",
    "        # Check group means\n",
    "        if \"max_group_means\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                b_index = np.logical_or(b_index, (df_gene_expr[c + \"_max\"] > filtering_criteria[\"max_group_means\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fold_change\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (np.abs(df_gene_expr[c + \"_fold\"]) > filtering_criteria[\"fold_change\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fdr_pvalue\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (df_gene_expr[c + \"_fold\"] < filtering_criteria[\"fdr_pvalue\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data matrix X\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_kos, ko_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for ko in all_kos:\n",
    "        # Retrieve the original name\n",
    "        locus_name = ko_dict[ko][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the information across species (we might have lost a bit of information for genes with no known Kegg Orthology) we will now analyse the results for the different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data array X (WITH VARIABLE LENGTH)\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_ogs, og_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for og in all_ogs:\n",
    "        # Retrieve the original name\n",
    "        locus_name = og_dict[og][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n",
    "\n",
    "def count_activated_genes(df_pathogen, locus_names, conditions, filters):\n",
    "    # Returns a count array of activation across conditions for multiple loci\n",
    "    # Returns both positive and negative counts\n",
    "    logf_col = [\"{}_logfold\".format(x) for x in conditions]\n",
    "    pval_col = [\"{}_p\".format(x) for x in conditions]\n",
    "    max_col = [\"{}_max\".format(x) for x in conditions]\n",
    "    ltag = 'new_locus_tag'\n",
    "    if df_pathogen['new_locus_tag'].isna().all():\n",
    "        ltag = 'old_locus_tag'\n",
    "    expr = df_pathogen[df_pathogen[ltag].isin(locus_names)][logf_col].to_numpy()\n",
    "    pv = df_pathogen[df_pathogen[ltag].isin(locus_names)][pval_col].to_numpy()\n",
    "    max_val = df_pathogen[df_pathogen[ltag].isin(locus_names)][max_col].to_numpy()\n",
    "    filter_p_max = np.logical_and(pv < filters['pvalue'], \n",
    "                                  max_val > filters['max'])\n",
    "    return np.logical_and(expr > filters['logfold'], filter_p_max).sum(axis=0), \\\n",
    "            np.logical_and(expr < -filters['logfold'], filter_p_max).sum(axis=0)\n",
    "    \n",
    "\n",
    "def get_activated_gene_count(df_pathogen, all_ogs, og_dict, idx, conditions, filters):\n",
    "    # Return a matrix with the count of genes above a determined threshold for each conditions\n",
    "    # Filters is a dict with a logfold and a pvalue entries\n",
    "    mat_upreg = []\n",
    "    mat_downreg = []\n",
    "    for og in all_ogs:\n",
    "        locus_names = og_dict[og][idx]\n",
    "        # If the KO doesn't have a mapping in this species return NaNs\n",
    "        if locus_names is None:\n",
    "            counts_up = np.empty((len(conditions),))\n",
    "            counts_up[:] = np.nan\n",
    "            counts_down = np.empty((len(conditions),))\n",
    "            counts_down[:] = np.nan\n",
    "        else:\n",
    "            counts_up, counts_down = count_activated_genes(df_pathogen, locus_names, conditions, filters)\n",
    "        mat_upreg.append(counts_up)\n",
    "        mat_downreg.append(counts_down)\n",
    "    return np.asarray(mat_upreg), np.asarray(mat_downreg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "Burkholderia pseudomallei K96243\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli UPEC 536\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "Helicobacter pylori G27\n",
      "Helicobacter pylori J99\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus¬†aureus MRSA252\n",
      "Staphylococcus¬†aureus MSSA476\n",
      "Staphylococcus¬†epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "# There will be one matrix per columns\n",
    "matrices_upregulated = dict()\n",
    "matrices_downregulated = dict()\n",
    "for c in columns:\n",
    "    matrices_upregulated[c] = []\n",
    "    matrices_downregulated[c] = []\n",
    "names = []\n",
    "expression_path = os.path.join(DATA_FOLDER, 'expression')\n",
    "\n",
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "condition_species_count = dict()\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    condition_species_count[cond] = 0\n",
    "\n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    name = \".\".join(file.split(\".\")[:-3])\n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    # Get all expressions\n",
    "    count_matrix_upreg, count_matrix_downreg = get_activated_gene_count(df_pathogen, \n",
    "                                                                        all_ogs, master_dict, \n",
    "                                                                        i, conditions, filters)\n",
    "    \n",
    "    # Count actual species count\n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: condition_species_count[col] += 1\n",
    "            \n",
    "    # Check for columns\n",
    "    col_eff = []\n",
    "    for j,col in enumerate(columns):\n",
    "        if (df_pathogen[col].isna()).all():\n",
    "            x_up = np.empty((len(all_ogs,)))\n",
    "            x_up[:] = None\n",
    "            x_down = np.empty((len(all_ogs,)))\n",
    "            x_down[:] = None\n",
    "        else:\n",
    "            x_up = count_matrix_upreg[:,j]\n",
    "            x_down = count_matrix_downreg[:,j]\n",
    "        matrices_upregulated[col].append(x_up)\n",
    "        matrices_downregulated[col].append(x_down)\n",
    "    names.append(name)\n",
    "    \n",
    "for col in columns:\n",
    "    matrices_upregulated[col] = np.asarray(matrices_upregulated[col]).T\n",
    "    matrices_downregulated[col] = np.asarray(matrices_downregulated[col]).T    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# SCORE COMPUTATION HERE\n",
    "# ----------------------------------------------------------------------\n",
    "NTOT = 32\n",
    "\n",
    "# New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "scores_combined_new = []\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "# 1. REGULAR SCORE, WITH ABSOLUTE COUNT\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_EGGNOG = os.path.join(OUTPUT_FOLDER, 'eggnog_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_EGGNOG, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"master_score.csv\"), index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_EGGNOG, \"absolute_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_df.loc[scores_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"absolute_score_top100\",\"{}_top100_on.csv\".format(cond)), index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directional score\n",
    "\n",
    "The directional score is a modification of the original score:\n",
    "\n",
    "$$S_{cond}=\\frac{1+ | n_{genes}(upreg)-n_{genes}(downreg)|}{1+n_{genes}(total)} \\frac{n_{species}(on)}{\\sqrt{n_{species}(total) \\cdot n_{species}(db)}} \\cdot log_2(1+n_{genes}(on))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SCORE WITH DIRECTIONALITY TAKEN INTO ACCOUNT\n",
    "scores_combined_new = []\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "    scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_new_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_EGGNOG = os.path.join(OUTPUT_FOLDER, 'eggnog_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_EGGNOG, exist_ok=True)\n",
    "master_scores_df = scores_new_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"master_directionality_score.csv\"), index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_EGGNOG, \"directionality_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_new_df.loc[scores_new_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on_upregulated'] = pd.DataFrame(matrices_upregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on_downregulated'] = pd.DataFrame(matrices_downregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_EGGNOG, \"directionality_score_top100\",\"{}_top100_on.csv\".format(cond)),\n",
    "                     index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores with subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group the bacteria in subclasses\n",
    "df_subgroups = pd.read_excel(os.path.join(DATA_FOLDER,'Groups_of_bacteria.xlsx'))\n",
    "\n",
    "# Get all unique classes\n",
    "GROUPS = ['Lifestyle', 'Infection', 'Class', 'Respiration', 'Gram St.']\n",
    "def get_unique_classes(ll):\n",
    "    # returns a truly unique set of values for each class\n",
    "    all_ll = []\n",
    "    for l in ll:\n",
    "        all_ll.extend([x.split(' ')[-1] for x in l.split(',')])\n",
    "    return np.unique(all_ll)\n",
    "\n",
    "def generate_bacteria_set(df_subgroup, group):\n",
    "    # Function that returns a list of species for each subgroup\n",
    "    subgroups = get_unique_classes(df_subgroup[group])\n",
    "    bacteria_dict = dict()\n",
    "    for subgroup in subgroups:\n",
    "        bact = []\n",
    "        for i, row in df_subgroup.iterrows():\n",
    "            if subgroup in [x.split(' ')[-1] for x in row[group].split(',')]:\n",
    "                bact.append(row['Species'])\n",
    "        bacteria_dict[subgroup] = bact\n",
    "    return bacteria_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "\tbs\n",
      "Burkholderia pseudomallei K96243\n",
      "\tbs\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli UPEC 536\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "\tbs\n",
      "Helicobacter pylori G27\n",
      "\tbs\n",
      "Helicobacter pylori J99\n",
      "\tbs\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "\tvic\n",
      "\tbs\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "\tvic\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus¬†aureus MRSA252\n",
      "Staphylococcus¬†aureus MSSA476\n",
      "Staphylococcus¬†epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "\tmig\n",
      "\tsp\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "species_condition_list = defaultdict(list)\n",
    "\n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    name = \".\".join(file.split(\".\")[:-3])\n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    \n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: \n",
    "            species_condition_list[name].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "\n",
    "def get_species_db(species_condition_list, species_subset):\n",
    "    # Count the exact number of species for each condition in a given subset\n",
    "    cond_dict = dict()\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        cond_dict[cond] = 0\n",
    "        for sp in species_subset:\n",
    "            if cond in species_condition_list[sp]:\n",
    "                cond_dict[cond] += 1\n",
    "    return cond_dict\n",
    "        \n",
    "\n",
    "# Count genes for subset only\n",
    "def count_total_genes_species_subset(index, master_dict, indeces):\n",
    "    c = 0\n",
    "    for l in np.array(master_dict[index], dtype=object)[indeces]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "\n",
    "# Function to compute the score for a subset of species:\n",
    "def get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 species_subset, species_condition_list, directionality=False):\n",
    "    # New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "    scores_combined_new = []\n",
    "    \n",
    "    # Get Species indeces\n",
    "    indeces = []\n",
    "    sp_names = []\n",
    "    for i,file in enumerate(filenames):\n",
    "        name = \".\".join(file.split(\".\")[:-3])\n",
    "        if name in species_subset:\n",
    "            indeces.append(i)\n",
    "            sp_names.append(name)\n",
    "            \n",
    "    ntot = len(species_subset)\n",
    "    # Get count of species\n",
    "    cond_dict_count = get_species_db(species_condition_list, species_subset)\n",
    "\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces]+\n",
    "                                matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "        \n",
    "        if directionality:\n",
    "            df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "            df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "\n",
    "        # Get the total number of gene for each KO\n",
    "        total_genes = np.array([count_total_genes_species_subset(i, master_dict, indeces) for i in df_count.index])\n",
    "\n",
    "        # Get the number of species for that condition\n",
    "        n_species_db = cond_dict_count[cond]\n",
    "\n",
    "        # Compute score\n",
    "        if directionality:\n",
    "            # Compute score\n",
    "            x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "            scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        else:\n",
    "            scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        scores_combined_new.append(scores.to_numpy())\n",
    "    logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "    scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n",
    "    master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "    master_scores_df['n_genes_total'] = [count_total_genes_species_subset(i, master_dict, indeces) for i in master_scores_df.index]\n",
    "    master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "    return master_scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in GROUPS:\n",
    "    # Mkdir \n",
    "    subgroups = get_unique_classes(df_subgroups[group])\n",
    "    bact_dict = generate_bacteria_set(df_subgroups, group)\n",
    "    for subgroup in subgroups:\n",
    "        # make directory\n",
    "        path = os.path.join(OUTPUT_FOLDER_EGGNOG, group, subgroup)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        # Get species subset:\n",
    "        sp_subset = bact_dict[subgroup]\n",
    "        master_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=False)\n",
    "        master_df.to_csv(os.path.join(path, \"eggnog_master_score.csv\"), index=True, header=True)\n",
    "\n",
    "        \n",
    "        scores_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=True)\n",
    "        master_df.to_csv(os.path.join(path, \"eggnog_master_directionality_score.csv\"), index=True, header=True)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "testvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Computation PATRIC\n",
    "Author: Matteo Togninalli\n",
    "\n",
    "This is a short notebook to explore the orthology data collected by Dr. Kemal Avican (Umeå University). The dataset is composed of orthology groups information from genes of the different species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "OUTPUT_FOLDER = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patric = pd.read_excel(os.path.join(DATA_FOLDER,'PATRIC','Acinetobacter baumannii strain AB5075-UW.xls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_genome_contig</th>\n",
       "      <th>ref_genome_gene</th>\n",
       "      <th>ref_genome_aa_length</th>\n",
       "      <th>ref_genome_patric_id</th>\n",
       "      <th>ref_genome_locus_tag</th>\n",
       "      <th>ref_genome_gene_name</th>\n",
       "      <th>ref_genome_plfam_id</th>\n",
       "      <th>ref_genome_pgfam_id</th>\n",
       "      <th>ref_genome_function</th>\n",
       "      <th>ref_genome_start</th>\n",
       "      <th>...</th>\n",
       "      <th>comp_genome_1_hit</th>\n",
       "      <th>comp_genome_1_contig</th>\n",
       "      <th>comp_genome_1_gene</th>\n",
       "      <th>comp_genome_1_aa_length</th>\n",
       "      <th>comp_genome_1_patric_id</th>\n",
       "      <th>comp_genome_1_locus_tag</th>\n",
       "      <th>comp_genome_1_gene_name</th>\n",
       "      <th>comp_genome_1_function</th>\n",
       "      <th>comp_genome_1_percent_identity</th>\n",
       "      <th>comp_genome_1_seq_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>fig|470.1345.peg.1</td>\n",
       "      <td>ABUW_0001</td>\n",
       "      <td>dnaA</td>\n",
       "      <td>PLF_469_00000962</td>\n",
       "      <td>PGF_00876106</td>\n",
       "      <td>Chromosomal replication initiator protein DnaA</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>465.0</td>\n",
       "      <td>ABUW_RS00005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>2</td>\n",
       "      <td>382</td>\n",
       "      <td>fig|470.1345.peg.2</td>\n",
       "      <td>ABUW_0002</td>\n",
       "      <td>dnaN</td>\n",
       "      <td>PLF_469_00001231</td>\n",
       "      <td>PGF_06473395</td>\n",
       "      <td>DNA polymerase III beta subunit (EC 2.7.7.7)</td>\n",
       "      <td>1590</td>\n",
       "      <td>...</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>382.0</td>\n",
       "      <td>ABUW_RS00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>fig|470.1345.peg.3</td>\n",
       "      <td>ABUW_0003</td>\n",
       "      <td>recF</td>\n",
       "      <td>PLF_469_00001108</td>\n",
       "      <td>PGF_10387199</td>\n",
       "      <td>DNA recombination and repair protein RecF</td>\n",
       "      <td>2753</td>\n",
       "      <td>...</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>ABUW_RS00015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>4</td>\n",
       "      <td>822</td>\n",
       "      <td>fig|470.1345.peg.4</td>\n",
       "      <td>ABUW_0004</td>\n",
       "      <td>gyrB</td>\n",
       "      <td>PLF_469_00000823</td>\n",
       "      <td>PGF_06703483</td>\n",
       "      <td>DNA gyrase subunit B (EC 5.99.1.3)</td>\n",
       "      <td>3888</td>\n",
       "      <td>...</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>822.0</td>\n",
       "      <td>ABUW_RS00020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>fig|470.1345.peg.5</td>\n",
       "      <td>ABUW_0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLF_469_00002758</td>\n",
       "      <td>PGF_00053521</td>\n",
       "      <td>Soluble cytochrome b562</td>\n",
       "      <td>6394</td>\n",
       "      <td>...</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>ABUW_RS00025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ref_genome_contig  ref_genome_gene  ref_genome_aa_length  \\\n",
       "0          CP008706                1                   465   \n",
       "1          CP008706                2                   382   \n",
       "2          CP008706                3                   360   \n",
       "3          CP008706                4                   822   \n",
       "4          CP008706                5                   130   \n",
       "\n",
       "  ref_genome_patric_id ref_genome_locus_tag ref_genome_gene_name  \\\n",
       "0   fig|470.1345.peg.1            ABUW_0001                 dnaA   \n",
       "1   fig|470.1345.peg.2            ABUW_0002                 dnaN   \n",
       "2   fig|470.1345.peg.3            ABUW_0003                 recF   \n",
       "3   fig|470.1345.peg.4            ABUW_0004                 gyrB   \n",
       "4   fig|470.1345.peg.5            ABUW_0005                  NaN   \n",
       "\n",
       "  ref_genome_plfam_id ref_genome_pgfam_id  \\\n",
       "0    PLF_469_00000962        PGF_00876106   \n",
       "1    PLF_469_00001231        PGF_06473395   \n",
       "2    PLF_469_00001108        PGF_10387199   \n",
       "3    PLF_469_00000823        PGF_06703483   \n",
       "4    PLF_469_00002758        PGF_00053521   \n",
       "\n",
       "                              ref_genome_function  ref_genome_start  ...  \\\n",
       "0  Chromosomal replication initiator protein DnaA                95  ...   \n",
       "1    DNA polymerase III beta subunit (EC 2.7.7.7)              1590  ...   \n",
       "2       DNA recombination and repair protein RecF              2753  ...   \n",
       "3              DNA gyrase subunit B (EC 5.99.1.3)              3888  ...   \n",
       "4                         Soluble cytochrome b562              6394  ...   \n",
       "\n",
       "   comp_genome_1_hit comp_genome_1_contig comp_genome_1_gene  \\\n",
       "0           bi (<->)                  NaN                NaN   \n",
       "1           bi (<->)                  NaN                NaN   \n",
       "2           bi (<->)                  NaN                NaN   \n",
       "3           bi (<->)                  NaN                NaN   \n",
       "4           bi (<->)                  NaN                NaN   \n",
       "\n",
       "   comp_genome_1_aa_length  comp_genome_1_patric_id  comp_genome_1_locus_tag  \\\n",
       "0                    465.0             ABUW_RS00005                      NaN   \n",
       "1                    382.0             ABUW_RS00010                      NaN   \n",
       "2                    360.0             ABUW_RS00015                      NaN   \n",
       "3                    822.0             ABUW_RS00020                      NaN   \n",
       "4                    130.0             ABUW_RS00025                      NaN   \n",
       "\n",
       "  comp_genome_1_gene_name  comp_genome_1_function  \\\n",
       "0                     NaN                     NaN   \n",
       "1                     NaN                     NaN   \n",
       "2                     NaN                     NaN   \n",
       "3                     NaN                     NaN   \n",
       "4                     NaN                     NaN   \n",
       "\n",
       "   comp_genome_1_percent_identity  comp_genome_1_seq_coverage  \n",
       "0                             1.0                       0.998  \n",
       "1                             1.0                       0.997  \n",
       "2                             1.0                       0.997  \n",
       "3                             1.0                       0.999  \n",
       "4                             1.0                       0.992  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of interest are ref_genome_locus_tag, ref_genome_patric_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patric = df_patric.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_genome_contig</th>\n",
       "      <th>ref_genome_gene</th>\n",
       "      <th>ref_genome_aa_length</th>\n",
       "      <th>ref_genome_patric_id</th>\n",
       "      <th>ref_genome_locus_tag</th>\n",
       "      <th>ref_genome_gene_name</th>\n",
       "      <th>ref_genome_plfam_id</th>\n",
       "      <th>ref_genome_pgfam_id</th>\n",
       "      <th>ref_genome_function</th>\n",
       "      <th>ref_genome_start</th>\n",
       "      <th>ref_genome_end</th>\n",
       "      <th>ref_genome_strand</th>\n",
       "      <th>comp_genome_1_hit</th>\n",
       "      <th>comp_genome_1_aa_length</th>\n",
       "      <th>comp_genome_1_patric_id</th>\n",
       "      <th>comp_genome_1_percent_identity</th>\n",
       "      <th>comp_genome_1_seq_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>fig|470.1345.peg.1</td>\n",
       "      <td>ABUW_0001</td>\n",
       "      <td>dnaA</td>\n",
       "      <td>PLF_469_00000962</td>\n",
       "      <td>PGF_00876106</td>\n",
       "      <td>Chromosomal replication initiator protein DnaA</td>\n",
       "      <td>95</td>\n",
       "      <td>1492</td>\n",
       "      <td>+</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>465.0</td>\n",
       "      <td>ABUW_RS00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>2</td>\n",
       "      <td>382</td>\n",
       "      <td>fig|470.1345.peg.2</td>\n",
       "      <td>ABUW_0002</td>\n",
       "      <td>dnaN</td>\n",
       "      <td>PLF_469_00001231</td>\n",
       "      <td>PGF_06473395</td>\n",
       "      <td>DNA polymerase III beta subunit (EC 2.7.7.7)</td>\n",
       "      <td>1590</td>\n",
       "      <td>2738</td>\n",
       "      <td>+</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>382.0</td>\n",
       "      <td>ABUW_RS00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>3</td>\n",
       "      <td>360</td>\n",
       "      <td>fig|470.1345.peg.3</td>\n",
       "      <td>ABUW_0003</td>\n",
       "      <td>recF</td>\n",
       "      <td>PLF_469_00001108</td>\n",
       "      <td>PGF_10387199</td>\n",
       "      <td>DNA recombination and repair protein RecF</td>\n",
       "      <td>2753</td>\n",
       "      <td>3835</td>\n",
       "      <td>+</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>360.0</td>\n",
       "      <td>ABUW_RS00015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>4</td>\n",
       "      <td>822</td>\n",
       "      <td>fig|470.1345.peg.4</td>\n",
       "      <td>ABUW_0004</td>\n",
       "      <td>gyrB</td>\n",
       "      <td>PLF_469_00000823</td>\n",
       "      <td>PGF_06703483</td>\n",
       "      <td>DNA gyrase subunit B (EC 5.99.1.3)</td>\n",
       "      <td>3888</td>\n",
       "      <td>6356</td>\n",
       "      <td>+</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>822.0</td>\n",
       "      <td>ABUW_RS00020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP008706</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>fig|470.1345.peg.5</td>\n",
       "      <td>ABUW_0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLF_469_00002758</td>\n",
       "      <td>PGF_00053521</td>\n",
       "      <td>Soluble cytochrome b562</td>\n",
       "      <td>6394</td>\n",
       "      <td>6786</td>\n",
       "      <td>+</td>\n",
       "      <td>bi (&lt;-&gt;)</td>\n",
       "      <td>130.0</td>\n",
       "      <td>ABUW_RS00025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ref_genome_contig  ref_genome_gene  ref_genome_aa_length  \\\n",
       "0          CP008706                1                   465   \n",
       "1          CP008706                2                   382   \n",
       "2          CP008706                3                   360   \n",
       "3          CP008706                4                   822   \n",
       "4          CP008706                5                   130   \n",
       "\n",
       "  ref_genome_patric_id ref_genome_locus_tag ref_genome_gene_name  \\\n",
       "0   fig|470.1345.peg.1            ABUW_0001                 dnaA   \n",
       "1   fig|470.1345.peg.2            ABUW_0002                 dnaN   \n",
       "2   fig|470.1345.peg.3            ABUW_0003                 recF   \n",
       "3   fig|470.1345.peg.4            ABUW_0004                 gyrB   \n",
       "4   fig|470.1345.peg.5            ABUW_0005                  NaN   \n",
       "\n",
       "  ref_genome_plfam_id ref_genome_pgfam_id  \\\n",
       "0    PLF_469_00000962        PGF_00876106   \n",
       "1    PLF_469_00001231        PGF_06473395   \n",
       "2    PLF_469_00001108        PGF_10387199   \n",
       "3    PLF_469_00000823        PGF_06703483   \n",
       "4    PLF_469_00002758        PGF_00053521   \n",
       "\n",
       "                              ref_genome_function  ref_genome_start  \\\n",
       "0  Chromosomal replication initiator protein DnaA                95   \n",
       "1    DNA polymerase III beta subunit (EC 2.7.7.7)              1590   \n",
       "2       DNA recombination and repair protein RecF              2753   \n",
       "3              DNA gyrase subunit B (EC 5.99.1.3)              3888   \n",
       "4                         Soluble cytochrome b562              6394   \n",
       "\n",
       "   ref_genome_end ref_genome_strand comp_genome_1_hit  \\\n",
       "0            1492                 +          bi (<->)   \n",
       "1            2738                 +          bi (<->)   \n",
       "2            3835                 +          bi (<->)   \n",
       "3            6356                 +          bi (<->)   \n",
       "4            6786                 +          bi (<->)   \n",
       "\n",
       "   comp_genome_1_aa_length comp_genome_1_patric_id  \\\n",
       "0                    465.0            ABUW_RS00005   \n",
       "1                    382.0            ABUW_RS00010   \n",
       "2                    360.0            ABUW_RS00015   \n",
       "3                    822.0            ABUW_RS00020   \n",
       "4                    130.0            ABUW_RS00025   \n",
       "\n",
       "   comp_genome_1_percent_identity  comp_genome_1_seq_coverage  \n",
       "0                             1.0                       0.998  \n",
       "1                             1.0                       0.997  \n",
       "2                             1.0                       0.997  \n",
       "3                             1.0                       0.999  \n",
       "4                             1.0                       0.992  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Achromobacter xylosoxidans strain SOLR10.xls',\n",
       " 'Acinetobacter baumannii strain AB5075-UW.xls',\n",
       " 'Aggregatibacter actinomycetemcomitans D7S-1.xls',\n",
       " 'Borrelia burgdorferi B31.xls',\n",
       " 'Burkholderia pseudomallei K96243.xls',\n",
       " 'Campylobacter jejuni subsp. jejuni 81-176.xls',\n",
       " 'Enterococcus faecalis OG1RF.xls',\n",
       " 'Escherichia coli 536 UPEC.xls',\n",
       " 'Escherichia coli ETEC H10407.xls',\n",
       " 'Escherichia coli O127H6 str. E2348:69 EPEC.xls',\n",
       " 'Francisella tularensis subsp. holarctica FSC200.xls',\n",
       " 'Haemophilus influenzae 86-028NP.xls',\n",
       " 'Helicobacter pylori G27.xls',\n",
       " 'Helicobacter pylori J99.xls',\n",
       " 'Klebsiella pneumoniae subsp. pneumoniae MGH 78578.xls',\n",
       " 'Legionella pneumophila subsp. pneumophila str. Philadelphia 1.xls',\n",
       " 'Listeria monocytogenes EGD-e.xls',\n",
       " 'Mycobacterium tuberculosis H37Ra.xls',\n",
       " 'Neisseria gonorrhoeae FA 1090.xls',\n",
       " 'Neisseria meningitidis FAM18.xls',\n",
       " 'Pseudomonas aeruginosa PAO1.xls',\n",
       " 'Salmonella enterica subsp. enterica serovar Typhimurium str. SL1344.xls',\n",
       " 'Shigella flexneri 5a str. M90T.xls',\n",
       " 'Staphylococcus aureus subsp. aureus MRSA252.xls',\n",
       " 'Staphylococcus aureus subsp. aureus MSSA476.xls',\n",
       " 'Staphylococcus epidermidis strain 1457.xls',\n",
       " 'Streptococcus agalactiae NEM316.xls',\n",
       " 'Streptococcus pneumoniae D39.xls',\n",
       " 'Streptococcus pyogenes strain 5448.xls',\n",
       " 'Streptococcus suis P1:7.xls',\n",
       " 'Vibrio cholerae O1 biovar El Tor str. N16961.xls',\n",
       " 'Yersinia pseudotuberculosis YPIII.xls']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to build dictionary tables to determine which Patric ids are referenced\n",
    "# First let's load all the files and concatenate them\n",
    "csv_path = os.path.join(DATA_FOLDER, 'PATRIC')\n",
    "filenames = []\n",
    "df_concat = []\n",
    "for file in os.listdir(csv_path):\n",
    "    # load the df\n",
    "    # Avoid junk files\n",
    "    if file[0] == '.':\n",
    "        continue\n",
    "    df_pathogen = pd.read_excel(os.path.join(csv_path, file))\n",
    "    filenames.append(file)\n",
    "    # Compute the number of genes\n",
    "    df_concat.append(df_pathogen)\n",
    "df_global = pd.concat(df_concat)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global = df_global.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109016, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33852"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For orthology groups: ref_genome_pgfam_id # Genes_locus_tags: comp_genome_1_patric_id\n",
    "df_global['ref_genome_pgfam_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearn dataframe further\n",
    "df_global = df_global.dropna(subset=['ref_genome_pgfam_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ogs = []\n",
    "for go in df_global['ref_genome_pgfam_id'].unique():\n",
    "    if go and go!= 'nan':\n",
    "        all_ogs.append(go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33852,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ogs = np.unique(all_ogs)\n",
    "all_ogs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "counter_all_ogs = dict()\n",
    "for og in all_ogs:\n",
    "    counter_all_ogs[og] = 0\n",
    "for df_patho in df_concat:\n",
    "    # Get all ko for that species\n",
    "    patho_ogs = []\n",
    "    for og_sp in df_patho['ref_genome_pgfam_id'].unique():\n",
    "        if og_sp and og_sp != 'nan':\n",
    "            if type(og_sp) == float and math.isnan(og_sp):\n",
    "                continue\n",
    "            counter_all_ogs[og_sp]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to build a dictionary for each species gene name to the GO\n",
    "# Assumption: we cluster GOs, irrespective if they match to more than one species\n",
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "\n",
    "def get_species_dict(df_patho):\n",
    "    og_dict = defaultdict(list)\n",
    "    locus_dict = dict()\n",
    "    # Build the gos map from\n",
    "    for locus, og_r in zip(df_patho['comp_genome_1_patric_id'], df_patho['ref_genome_pgfam_id']):\n",
    "        locus_dict[locus] = og_r\n",
    "        if og_r and og_r != 'nan':\n",
    "            if type(og_r) == float and math.isnan(og_r):\n",
    "                continue\n",
    "            og_dict[og_r].append(locus)\n",
    "    return og_dict, locus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a master dictionary for all OGs\n",
    "master_dict = defaultdict(list)\n",
    "loci_dict = []\n",
    "for df_patho in df_concat:\n",
    "    o_dict, l_dict = get_species_dict(df_patho)\n",
    "    loci_dict.append(l_dict)\n",
    "    for og in all_ogs:\n",
    "        if og in o_dict:\n",
    "            master_dict[og].append(o_dict[og])\n",
    "        else:\n",
    "            master_dict[og].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the list of genes for each orthology group.\n",
    "columns = ['.'.join(f.split('.')[:-1]) for f in filenames]\n",
    "df_og_mapping = pd.DataFrame.from_dict(master_dict, orient='index', columns=columns)\n",
    "\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "df_og_mapping['n_genes_total'] = df_og_mapping.index.map(lambda x: count_total_genes(x, master_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33852, 33)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_og_mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "df_og_mapping.to_csv(os.path.join(OUTPUT_FOLDER, 'Patric_gene_list.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the gene expression matrix, one for each condition\n",
    "# Utility functions\n",
    "# Rename columns for faster access later on\n",
    "def clean_dataframe(df_gene_expr):\n",
    "    # Quick function to get rid of log fold change columns and to rename columns\n",
    "    # condition_max, condition_fold, condition_p, condition_p_fdr, condition_p_bonf\n",
    "    # First, drop the columns after 75\n",
    "    # Some species have, for some reason, more meta-information\n",
    "    meta_columns = 9\n",
    "    if df_gene_expr.shape[1]>219:\n",
    "        # Some files have more meta columns...\n",
    "        meta_columns = 14\n",
    "        \n",
    "    df_gene_expr = df_gene_expr.drop(columns=df_gene_expr.columns[66+meta_columns:])\n",
    "    \n",
    "    # Find conditions names\n",
    "    unique_conditions = list(set(map(lambda x: x.split(' ')[0], df_gene_expr.columns[meta_columns:].tolist())))\n",
    "    # Create new keys dictionnary:\n",
    "    new_keys = dict()\n",
    "    for column in df_gene_expr.columns[5:].tolist():\n",
    "        if column.split(\" \")[-1] == \"means\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_max\"\n",
    "        elif column.split(\" \")[-1] == \"change\":\n",
    "            if column.split(\" \")[-2] == \"fold\":\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_logfold\"\n",
    "            else:\n",
    "                new_keys[column] = column.split(\" \")[0] + \"_fold\"\n",
    "        elif column.split(\" \")[-1] == \"P-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p\"\n",
    "        elif column.split(\" \")[-1] == \"p-value\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_fdr\"\n",
    "        elif column.split(\" \")[-1] == \"Bonferroni\":\n",
    "            new_keys[column] = column.split(\" \")[0] + \"_p_bonf\"\n",
    "    return df_gene_expr.rename(new_keys, axis=\"columns\").rename(str.lower, axis=\"columns\")\n",
    "\n",
    "def count_genes_with_filtering(df_gene_expr, filtering_criteria=None):\n",
    "    # Returns the number of genes with a specific set of filtering criteria \n",
    "    # passed as a dictionary of fold_change, max_group_means and fdr_pvalue\n",
    "    # If no criteria are passed, simply returns the total number of genes\n",
    "    if filtering_criteria == None:\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    else:\n",
    "        # Check group means\n",
    "        if \"max_group_means\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                b_index = np.logical_or(b_index, (df_gene_expr[c + \"_max\"] > filtering_criteria[\"max_group_means\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fold_change\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (np.abs(df_gene_expr[c + \"_fold\"]) > filtering_criteria[\"fold_change\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        if \"fdr_pvalue\" in filtering_criteria:\n",
    "            b_index = np.zeros(df_gene_expr.shape[0],dtype=bool)\n",
    "            for c in CONDITIONS:\n",
    "                # filter a gene out if NONE of its responses are larger than XX:\n",
    "                 b_index = np.logical_or(b_index, (df_gene_expr[c + \"_fold\"] < filtering_criteria[\"fdr_pvalue\"]))\n",
    "            df_gene_expr = df_gene_expr.loc[b_index]\n",
    "        return df_gene_expr.shape[0], df_gene_expr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data matrix X\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_kos, ko_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for ko in all_kos:\n",
    "        # Retrieve the original name\n",
    "        locus_name = ko_dict[ko][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the information across species (we might have lost a bit of information for genes with no known Kegg Orthology) we will now analyse the results for the different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes and save values in data array X (WITH VARIABLE LENGTH)\n",
    "# Reproduce and save the matrix scatter for all species.\n",
    "\n",
    "def get_gene_expr(df_pathogen, all_ogs, og_dict, idx, columns):\n",
    "    # Return a matrix with the gene expression for the different KOs and NaN if they are missing\n",
    "    # It will then be chopped in slices for the condition-specific matrices\n",
    "    # Idx is the index of the species in the master_dict list order, (see above)\n",
    "    mat = []\n",
    "    for og in all_ogs:\n",
    "        # Retrieve the original name\n",
    "        locus_name = og_dict[og][idx]\n",
    "        if locus_name is not None:\n",
    "            locus_name = locus_name[0]\n",
    "        if locus_name is None or ((df_pathogen['old_locus_tag']==locus_name).sum() == 0 \n",
    "                                  and (df_pathogen['new_locus_tag']==locus_name).sum() == 0):\n",
    "            expr = np.empty((len(columns),))\n",
    "            expr[:] = np.nan\n",
    "        else:\n",
    "            # Careful, we need to use non-filtered datasets to avoid losing information...\n",
    "            if (df_pathogen['new_locus_tag'].apply(str)==locus_name).sum() == 0:\n",
    "                expr = df_pathogen[df_pathogen['old_locus_tag']==locus_name][columns].to_numpy()\n",
    "            else:\n",
    "                expr = df_pathogen[df_pathogen['new_locus_tag'].apply(str)==locus_name][columns].to_numpy()\n",
    "            expr = expr.ravel()[:len(columns)] # Here we only take the values of the first matching locus\n",
    "        mat.append(expr)\n",
    "    return np.asarray(mat)\n",
    "\n",
    "def count_activated_genes(df_pathogen, locus_names, conditions, filters):\n",
    "    # Returns a count array of activation across conditions for multiple loci\n",
    "    # Returns both positive and negative counts\n",
    "    logf_col = [\"{}_logfold\".format(x) for x in conditions]\n",
    "    pval_col = [\"{}_p\".format(x) for x in conditions]\n",
    "    max_col = [\"{}_max\".format(x) for x in conditions]\n",
    "    ltag = 'new_locus_tag'\n",
    "    if df_pathogen['new_locus_tag'].isna().all():\n",
    "        ltag = 'old_locus_tag'\n",
    "    expr = df_pathogen[df_pathogen[ltag].isin(locus_names)][logf_col].to_numpy()\n",
    "    pv = df_pathogen[df_pathogen[ltag].isin(locus_names)][pval_col].to_numpy()\n",
    "    max_val = df_pathogen[df_pathogen[ltag].isin(locus_names)][max_col].to_numpy()\n",
    "    filter_p_max = np.logical_and(pv < filters['pvalue'], \n",
    "                                  max_val > filters['max'])\n",
    "    return np.logical_and(expr > filters['logfold'], filter_p_max).sum(axis=0), \\\n",
    "            np.logical_and(expr < -filters['logfold'], filter_p_max).sum(axis=0)\n",
    "    \n",
    "\n",
    "def get_activated_gene_count(df_pathogen, all_ogs, og_dict, idx, conditions, filters):\n",
    "    # Return a matrix with the count of genes above a determined threshold for each conditions\n",
    "    # Filters is a dict with a logfold and a pvalue entries\n",
    "    mat_upreg = []\n",
    "    mat_downreg = []\n",
    "    for og in all_ogs:\n",
    "        locus_names = og_dict[og][idx]\n",
    "        # If the KO doesn't have a mapping in this species return NaNs\n",
    "        if locus_names is None:\n",
    "            counts_up = np.empty((len(conditions),))\n",
    "            counts_up[:] = np.nan\n",
    "            counts_down = np.empty((len(conditions),))\n",
    "            counts_down[:] = np.nan\n",
    "        else:\n",
    "            counts_up, counts_down = count_activated_genes(df_pathogen, locus_names, conditions, filters)\n",
    "        mat_upreg.append(counts_up)\n",
    "        mat_downreg.append(counts_down)\n",
    "    return np.asarray(mat_upreg), np.asarray(mat_downreg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "\tbs\n",
      "Burkholderia pseudomallei K96243\n",
      "\tbs\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli UPEC 536\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "\tbs\n",
      "Helicobacter pylori G27\n",
      "\tbs\n",
      "Helicobacter pylori J99\n",
      "\tbs\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "\tbs\n",
      "\tvic\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "\tvic\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus aureus MRSA252\n",
      "Staphylococcus aureus MSSA476\n",
      "Staphylococcus epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "\tsp\n",
      "\tmig\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "# There will be one matrix per columns\n",
    "matrices_upregulated = dict()\n",
    "matrices_downregulated = dict()\n",
    "for c in columns:\n",
    "    matrices_upregulated[c] = []\n",
    "    matrices_downregulated[c] = []\n",
    "names = []\n",
    "expression_path = os.path.join(DATA_FOLDER, 'expression')\n",
    "\n",
    "# Add manual checks for issues:\n",
    "manual_dict = {\n",
    "    'Streptococcus suis P1:7.xls' : 'Streptococcus suis S10 P 17',\n",
    "    'Neisseria meningitidis FAM18.xls' : 'Neisseria meningitidis serogroup C FAM18',\n",
    "    'Salmonella enterica subsp. enterica serovar Typhimurium str. SL1344.xls': 'Salmonella enterica subsp. enterica serovar TyphimuriumSL1344',\n",
    "    'Escherichia coli 536 UPEC.xls': 'Escherichia coli UPEC 536',\n",
    "    'Legionella pneumophila subsp. pneumophila str. Philadelphia 1.xls': 'Legionella pneumophila subsp. pneumophila Philadelphia 1',\n",
    "    'Staphylococcus aureus subsp. aureus MSSA476.xls': 'Staphylococcus\\xa0aureus MSSA476',\n",
    "    'Staphylococcus aureus subsp. aureus MRSA252.xls': 'Staphylococcus\\xa0aureus MRSA252',\n",
    "    'Escherichia coli O127H6 str. E2348:69 EPEC.xls': 'Escherichia coli EPEC 0127 H6 E2348 69'\n",
    "}\n",
    "\n",
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "condition_species_count = dict()\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    condition_species_count[cond] = 0\n",
    "    \n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    # Ugly filename fixes\n",
    "    if file in manual_dict:\n",
    "        name = manual_dict[file]\n",
    "    else:\n",
    "        name = \".\".join(file.split(\".\")[:-1])\n",
    "        name = ''.join(name.split('strain '))\n",
    "        name = name.replace('Staphylococcus ','Staphylococcus\\xa0')\n",
    "    \n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    \n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: condition_species_count[col] += 1\n",
    "    \n",
    "    # Get all expressions\n",
    "    count_matrix_upreg, count_matrix_downreg = get_activated_gene_count(df_pathogen, \n",
    "                                                                        all_ogs, master_dict, \n",
    "                                                                        i, conditions, filters)\n",
    "    # Check for columns\n",
    "    col_eff = []\n",
    "    for j,col in enumerate(columns):\n",
    "        if (df_pathogen[col].isna()).all():\n",
    "            x_up = np.empty((len(all_ogs,)))\n",
    "            x_up[:] = None\n",
    "            x_down = np.empty((len(all_ogs,)))\n",
    "            x_down[:] = None\n",
    "        else:\n",
    "            x_up = count_matrix_upreg[:,j]\n",
    "            x_down = count_matrix_downreg[:,j]\n",
    "        matrices_upregulated[col].append(x_up)\n",
    "        matrices_downregulated[col].append(x_down)\n",
    "    names.append(name)\n",
    "for col in columns:\n",
    "    matrices_upregulated[col] = np.asarray(matrices_upregulated[col]).T\n",
    "    matrices_downregulated[col] = np.asarray(matrices_downregulated[col]).T    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans strain SOLR10.xls\n",
      "Acinetobacter baumannii strain AB5075-UW.xls\n",
      "Escherichia coli 536 UPEC.xls\n",
      "Escherichia coli O127H6 str. E2348:69 EPEC.xls\n",
      "Legionella pneumophila subsp. pneumophila str. Philadelphia 1.xls\n",
      "Neisseria meningitidis FAM18.xls\n",
      "Salmonella enterica subsp. enterica serovar Typhimurium str. SL1344.xls\n",
      "Staphylococcus aureus subsp. aureus MRSA252.xls\n",
      "Staphylococcus aureus subsp. aureus MSSA476.xls\n",
      "Staphylococcus epidermidis strain 1457.xls\n",
      "Streptococcus pyogenes strain 5448.xls\n",
      "Streptococcus suis P1:7.xls\n"
     ]
    }
   ],
   "source": [
    "original_fnames = ['Shigella flexneri 5a str. M90T.txt.emapper.annotations',\n",
    " 'Escherichia coli ETEC H10407.txt.emapper.annotations',\n",
    " 'Neisseria meningitidis serogroup C FAM18.txt.emapper.annotations',\n",
    " 'Escherichia coli EPEC 0127 H6 E2348 69.txt.emapper.annotations',\n",
    " 'Yersinia pseudotuberculosis YPIII.txt.emapper.annotations',\n",
    " 'Borrelia burgdorferi B31.txt.emapper.annotations',\n",
    " 'Salmonella enterica subsp. enterica serovar TyphimuriumSL1344.txt.emapper.annotations',\n",
    " 'Staphylococcus\\xa0epidermidis 1457.txt.emapper.annotations',\n",
    " 'Streptococcus agalactiae NEM316.txt.emapper.annotations',\n",
    " 'Klebsiella pneumoniae subsp. pneumoniae MGH 78578.txt.emapper.annotations',\n",
    " 'Staphylococcus\\xa0aureus MRSA252.txt.emapper.annotations',\n",
    " 'Staphylococcus\\xa0aureus MSSA476.txt.emapper.annotations',\n",
    " 'Neisseria gonorrhoeae FA 1090.txt.emapper.annotations',\n",
    " 'Escherichia coli UPEC 536.txt.emapper.annotations',\n",
    " 'Helicobacter pylori J99.txt.emapper.annotations',\n",
    " 'Acinetobacter baumannii AB5075-UW.txt.emapper.annotations',\n",
    " 'Enterococcus faecalis OG1RF.txt.emapper.annotations',\n",
    " 'Campylobacter jejuni subsp. jejuni 81-176.txt.emapper.annotations',\n",
    " 'Haemophilus influenzae 86-028NP.txt.emapper.annotations',\n",
    " 'Streptococcus pneumoniae D39.txt.emapper.annotations',\n",
    " 'Pseudomonas aeruginosa PAO1.txt.emapper.annotations',\n",
    " 'Aggregatibacter actinomycetemcomitans D7S-1.txt.emapper.annotations',\n",
    " 'Mycobacterium tuberculosis H37Ra.txt.emapper.annotations',\n",
    " 'Helicobacter pylori G27.txt.emapper.annotations',\n",
    " 'Streptococcus suis S10 P 17.txt.emapper.annotations',\n",
    " 'Streptococcus pyogenes 5448.txt.emapper.annotations',\n",
    " 'Listeria monocytogenes EGD-e.txt.emapper.annotations',\n",
    " 'Legionella pneumophila subsp. pneumophila Philadelphia 1.txt.emapper.annotations',\n",
    " 'Francisella tularensis subsp. holarctica FSC200.txt.emapper.annotations',\n",
    " 'Achromobacter xylosoxidans SOLR10.txt.emapper.annotations',\n",
    " 'Burkholderia pseudomallei K96243.txt.emapper.annotations',\n",
    " 'Vibrio cholerae O1 biovar El Tor str. N16961.txt.emapper.annotations']\n",
    "original_fnames = [\".\".join(file.split(\".\")[:-3])+'.xls' for file in original_fnames]\n",
    "\n",
    "\n",
    "for fname in filenames:\n",
    "    if fname not in original_fnames:\n",
    "        print(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# SCORE COMPUTATION HERE\n",
    "# ----------------------------------------------------------------------\n",
    "NTOT = 32\n",
    "\n",
    "# New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "scores_combined_new = []\n",
    "# Need to count ALL gene copies (not only the on ones)\n",
    "def count_total_genes(index, master_dict):\n",
    "    c = 0\n",
    "    for l in master_dict[index]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "# 1. REGULAR SCORE, WITH ABSOLUTE COUNT\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_PATRIC = os.path.join(OUTPUT_FOLDER, 'patric_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_PATRIC, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_PATRIC, \"master_absolute_score.csv\"), index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_PATRIC, \"absolute_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_df.loc[scores_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_PATRIC, \"absolute_score_top100\", \"{}_top100_on.csv\".format(cond)),\n",
    "                     index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directional score\n",
    "\n",
    "The directional score is a modification of the original score:\n",
    "\n",
    "$$S_{cond}=\\frac{1+ | n_{genes}(upreg)-n_{genes}(downreg)|}{1+n_{genes}(total)} \\frac{n_{species}(on)}{\\sqrt{n_{species}(total) \\cdot n_{species}(db)}} \\cdot log_2(1+n_{genes}(on))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. SCORE WITH DIRECTIONALITY TAKEN INTO ACCOUNT\n",
    "scores_combined_new = []\n",
    "for cond in sorted(list(CONDITIONS)):\n",
    "    df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"]+\n",
    "                            matrices_downregulated[cond + \"_logfold\"], index=all_ogs, columns=names)\n",
    "    \n",
    "    # Get the total number of gene for each KO\n",
    "    total_genes = np.array([count_total_genes(i, master_dict) for i in df_count.index])\n",
    "    \n",
    "    # Get the number of species for that condition\n",
    "    n_species_db = condition_species_count[cond]\n",
    "    \n",
    "    # Compute score\n",
    "    x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "    scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "        (df_count>0).sum(axis=1), np.sqrt(NTOT-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "    scores_combined_new.append(scores.to_numpy())\n",
    "logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "scores_new_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER_PATRIC = os.path.join(OUTPUT_FOLDER, 'patric_scores')\n",
    "os.makedirs(OUTPUT_FOLDER_PATRIC, exist_ok=True)\n",
    "master_scores_df = scores_new_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "master_scores_df['n_genes_total'] = [count_total_genes(i, master_dict) for i in master_scores_df.index]\n",
    "master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "master_scores_df.to_csv(os.path.join(OUTPUT_FOLDER_PATRIC, \"master_directionality_score.csv\"), \n",
    "                        index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(OUTPUT_FOLDER_PATRIC, \"directionality_score_top100\"), exist_ok=True)\n",
    "for cond in logfold_columns:\n",
    "    df_tofile = scores_new_df.loc[scores_new_df[cond].dropna().sort_values()[-500:].index[::-1]]\n",
    "    df = pd.DataFrame(matrices_upregulated[cond]+matrices_downregulated[cond], index=all_ogs, columns=names)\n",
    "    df_tofile['n_species'] = NTOT-df.isna().sum(axis=1)\n",
    "    df_tofile['n_on_upregulated'] = pd.DataFrame(matrices_upregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on_downregulated'] = pd.DataFrame(matrices_downregulated[cond], index=all_ogs, columns=names).sum(axis=1)\n",
    "    df_tofile['n_on'] = df.sum(axis=1)\n",
    "    df_tofile['n_species_on'] = (df>0).sum(axis=1)\n",
    "    df_tofile['n_genes_total'] = [count_total_genes(i, master_dict) for i in df_tofile.index]\n",
    "    df_tofile.to_csv(os.path.join(OUTPUT_FOLDER_PATRIC, \"directionality_score_top100\", \"{}_top100_on.csv\".format(cond)),\n",
    "                     index=True, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores with subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group the bacteria in subclasses\n",
    "df_subgroups = pd.read_excel(os.path.join(DATA_FOLDER,'Groups_of_bacteria.xlsx'))\n",
    "\n",
    "# Get all unique classes\n",
    "GROUPS = ['Lifestyle', 'Infection', 'Class', 'Respiration', 'Gram St.']\n",
    "def get_unique_classes(ll):\n",
    "    # returns a truly unique set of values for each class\n",
    "    all_ll = []\n",
    "    for l in ll:\n",
    "        all_ll.extend([x.split(' ')[-1] for x in l.split(',')])\n",
    "    return np.unique(all_ll)\n",
    "\n",
    "def generate_bacteria_set(df_subgroup, group):\n",
    "    # Function that returns a list of species for each subgroup\n",
    "    subgroups = get_unique_classes(df_subgroup[group])\n",
    "    bacteria_dict = dict()\n",
    "    for subgroup in subgroups:\n",
    "        bact = []\n",
    "        for i, row in df_subgroup.iterrows():\n",
    "            if subgroup in [x.split(' ')[-1] for x in row[group].split(',')]:\n",
    "                bact.append(row['Species'])\n",
    "        bacteria_dict[subgroup] = bact\n",
    "    return bacteria_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achromobacter xylosoxidans SOLR10\n",
      "Acinetobacter baumannii AB5075-UW\n",
      "Aggregatibacter actinomycetemcomitans D7S-1\n",
      "Borrelia burgdorferi B31\n",
      "\tbs\n",
      "Burkholderia pseudomallei K96243\n",
      "\tbs\n",
      "Campylobacter jejuni subsp. jejuni 81-176\n",
      "Enterococcus faecalis OG1RF\n",
      "Escherichia coli UPEC 536\n",
      "Escherichia coli ETEC H10407\n",
      "Escherichia coli EPEC 0127 H6 E2348 69\n",
      "Francisella tularensis subsp. holarctica FSC200\n",
      "Haemophilus influenzae 86-028NP\n",
      "\tbs\n",
      "Helicobacter pylori G27\n",
      "\tbs\n",
      "Helicobacter pylori J99\n",
      "\tbs\n",
      "Klebsiella pneumoniae subsp. pneumoniae MGH 78578\n",
      "Legionella pneumophila subsp. pneumophila Philadelphia 1\n",
      "\tbs\n",
      "\tvic\n",
      "Listeria monocytogenes EGD-e\n",
      "Mycobacterium tuberculosis H37Ra\n",
      "\tvic\n",
      "Neisseria gonorrhoeae FA 1090\n",
      "Neisseria meningitidis serogroup C FAM18\n",
      "Pseudomonas aeruginosa PAO1\n",
      "Salmonella enterica subsp. enterica serovar TyphimuriumSL1344\n",
      "Shigella flexneri 5a str. M90T\n",
      "Staphylococcus aureus MRSA252\n",
      "Staphylococcus aureus MSSA476\n",
      "Staphylococcus epidermidis 1457\n",
      "Streptococcus agalactiae NEM316\n",
      "Streptococcus pneumoniae D39\n",
      "Streptococcus pyogenes 5448\n",
      "Streptococcus suis S10 P 17\n",
      "\tsp\n",
      "\tmig\n",
      "Vibrio cholerae O1 biovar El Tor str. N16961\n",
      "Yersinia pseudotuberculosis YPIII\n"
     ]
    }
   ],
   "source": [
    "# !! FOR SOME CONDITIONS, 2 SPECIES COULD NOT BE MEASURED ==> n_species(db) is 30 and not 32\n",
    "species_condition_list = defaultdict(list)\n",
    "\n",
    "for i,file in enumerate(filenames): # this way we follow the order\n",
    "    # load the df\n",
    "    if file in manual_dict:\n",
    "        name = manual_dict[file]\n",
    "    else:\n",
    "        name = \".\".join(file.split(\".\")[:-1])\n",
    "        name = ''.join(name.split('strain '))\n",
    "        name = name.replace('Staphylococcus ','Staphylococcus\\xa0')\n",
    "    \n",
    "    filename = name+\".xlsx\"\n",
    "    print(name)\n",
    "    df_pathogen = pd.read_excel(os.path.join(expression_path,filename), na_values=['#NUM!'])\n",
    "    df_pathogen = clean_dataframe(df_pathogen)\n",
    "    \n",
    "    for j,col in enumerate(list(CONDITIONS)):\n",
    "        if (df_pathogen[col+\"_logfold\"].isna()).all():\n",
    "            print('\\t'+col)\n",
    "        else: \n",
    "            species_condition_list[name].append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITIONS = set(['li', 'ns', 'mig', 'bs', 'tm', 'oxs', 'vic', 'sp', 'as', 'oss', 'nd'])\n",
    "filters = {'logfold':0.8, 'pvalue':0.05, 'max': 20}\n",
    "columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "columns_all = columns + [\"{}_p\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "conditions = sorted(list(CONDITIONS))\n",
    "\n",
    "def get_species_db(species_condition_list, species_subset):\n",
    "    # Count the exact number of species for each condition in a given subset\n",
    "    cond_dict = dict()\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        cond_dict[cond] = 0\n",
    "        for sp in species_subset:\n",
    "            if cond in species_condition_list[sp]:\n",
    "                cond_dict[cond] += 1\n",
    "    return cond_dict\n",
    "        \n",
    "\n",
    "# Count genes for subset only\n",
    "def count_total_genes_species_subset(index, master_dict, indeces):\n",
    "    c = 0\n",
    "    for l in np.array(master_dict[index], dtype=object)[indeces]:\n",
    "        if l is None:\n",
    "            continue\n",
    "        c+= len(l)\n",
    "    return c\n",
    "\n",
    "\n",
    "# Function to compute the score for a subset of species:\n",
    "def get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 species_subset, species_condition_list, directionality=False):\n",
    "    # New array where we report n_on, n_species and n_on/n_total*n_on_species/n_species\n",
    "    scores_combined_new = []\n",
    "    \n",
    "    # Get Species indeces\n",
    "    indeces = []\n",
    "    sp_names = []\n",
    "    for i,file in enumerate(filenames):\n",
    "        if file in manual_dict:\n",
    "            name = manual_dict[file]\n",
    "        else:\n",
    "            name = \".\".join(file.split(\".\")[:-1])\n",
    "            name = ''.join(name.split('strain '))\n",
    "            name = name.replace('Staphylococcus ','Staphylococcus\\xa0')\n",
    "        if name in species_subset:\n",
    "            indeces.append(i)\n",
    "            sp_names.append(name)\n",
    "            \n",
    "    ntot = len(species_subset)\n",
    "    # Get count of species\n",
    "    cond_dict_count = get_species_db(species_condition_list, species_subset)\n",
    "\n",
    "    for cond in sorted(list(CONDITIONS)):\n",
    "        df_count = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces]+\n",
    "                                matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "        \n",
    "        if directionality:\n",
    "            df_count_up = pd.DataFrame(matrices_upregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "            df_count_down = pd.DataFrame(matrices_downregulated[cond + \"_logfold\"][:,indeces], index=all_ogs, columns=sp_names)\n",
    "\n",
    "        # Get the total number of gene for each KO\n",
    "        total_genes = np.array([count_total_genes_species_subset(i, master_dict, indeces) for i in df_count.index])\n",
    "\n",
    "        # Get the number of species for that condition\n",
    "        n_species_db = cond_dict_count[cond]\n",
    "\n",
    "        # Compute score\n",
    "        if directionality:\n",
    "            # Compute score\n",
    "            x_comp = np.abs(df_count_up.sum(axis=1)-df_count_down.sum(axis=1))\n",
    "            scores = np.divide(1+x_comp, 1+total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        else:\n",
    "            scores = np.divide(df_count.sum(axis=1), total_genes)*np.divide(\n",
    "                (df_count>0).sum(axis=1), np.sqrt(ntot-df_count.isna().sum(axis=1)))/np.sqrt(n_species_db)*np.log2(1+df_count.sum(axis=1))\n",
    "        scores_combined_new.append(scores.to_numpy())\n",
    "    logfold_columns = [\"{}_logfold\".format(c) for c in sorted(list(CONDITIONS))]\n",
    "    scores_df = pd.DataFrame(np.asarray(scores_combined_new).T, index=all_ogs, columns=logfold_columns)\n",
    "    master_scores_df = scores_df.applymap(lambda x: \"{:.4f}\".format(x))\n",
    "    master_scores_df['n_genes_total'] = [count_total_genes_species_subset(i, master_dict, indeces) for i in master_scores_df.index]\n",
    "    master_scores_df = master_scores_df[master_scores_df['n_genes_total']>1]\n",
    "    return master_scores_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in GROUPS:\n",
    "    # Mkdir \n",
    "    subgroups = get_unique_classes(df_subgroups[group])\n",
    "    bact_dict = generate_bacteria_set(df_subgroups, group)\n",
    "    for subgroup in subgroups:\n",
    "        # make directory\n",
    "        path = os.path.join(OUTPUT_FOLDER_PATRIC,'scores_per_group', group, subgroup)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        # Get species subset:\n",
    "        sp_subset = bact_dict[subgroup]\n",
    "        master_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=False)\n",
    "        master_df.to_csv(os.path.join(path, \"patric_master_score.csv\"), index=True, header=True)\n",
    "\n",
    "        \n",
    "        scores_df = get_score_df(matrices_upregulated, matrices_downregulated, all_ogs, master_dict, \n",
    "                 sp_subset, species_condition_list, directionality=True)\n",
    "        master_df.to_csv(os.path.join(path, \"patric_master_directionality_score.csv\"), index=True, header=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
